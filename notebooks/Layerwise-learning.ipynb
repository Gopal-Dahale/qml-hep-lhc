{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2154bf44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T04:45:05.981157Z",
     "start_time": "2022-07-28T04:45:01.331092Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from importlib.util import find_spec\n",
    "if find_spec(\"qml_hep_lhc\") is None:\n",
    "    import sys\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cbf0a7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T04:46:12.686343Z",
     "start_time": "2022-07-28T04:45:06.622166Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 10:15:27.187239: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-28 10:15:27.187330: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-07-28 10:16:04.814825: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-07-28 10:16:04.814921: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (bhagvada): /proc/driver/nvidia/version does not exist\n",
      "2022-07-28 10:16:04.837258: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cirq\n",
    "import sympy\n",
    "import numpy as np\n",
    "import tensorflow_quantum as tfq\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from qml_hep_lhc.data import QuarkGluon, ElectronPhoton,MNIST\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import argparse\n",
    "\n",
    "from tensorflow.keras.layers import Layer, Flatten, Activation\n",
    "from qml_hep_lhc.ansatzes.utils import cluster_state_circuit\n",
    "import cirq\n",
    "import sympy as sp\n",
    "import numpy as np\n",
    "from tensorflow import random_uniform_initializer, Variable, constant, repeat, tile, shape, gather, pad\n",
    "import tensorflow_quantum as tfq\n",
    "from tensorflow import multiply, add\n",
    "\n",
    "from tensorflow.keras.layers import Layer, Concatenate, Reshape, Add, Activation\n",
    "from qml_hep_lhc.layers.utils import normalize_padding, normalize_tuple, convolution_iters, get_count_of_qubits, get_num_in_symbols\n",
    "from qml_hep_lhc.utils import _import_class\n",
    "import cirq\n",
    "import numpy as np\n",
    "from tensorflow import pad\n",
    "from qml_hep_lhc.layers import TwoLayerPQC\n",
    "\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, MaxPool2D\n",
    "from qml_hep_lhc.models.base_model import BaseModel\n",
    "import numpy as np\n",
    "from qml_hep_lhc.layers.utils import get_count_of_qubits, get_num_in_symbols\n",
    "from qml_hep_lhc.utils import _import_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f7f0d1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T08:26:49.488145Z",
     "start_time": "2022-07-28T08:26:49.393543Z"
    }
   },
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n",
    "args.dataset_type = 'med'\n",
    "args.center_crop = 0.2\n",
    "args.standardize = 1\n",
    "args.percent_samples = 0.05\n",
    "args.optimizer = 'Ranger'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d29af44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T04:46:17.927127Z",
     "start_time": "2022-07-28T04:46:16.351701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center cropping...\n",
      "Center cropping...\n",
      "Standardizing data...\n",
      "\n",
      "Dataset :Electron Photon med\n",
      "╒════════╤════════════════╤═══════════════╤═══════════════╤═══════════╕\n",
      "│ Data   │ Train size     │ Val size      │ Test size     │ Dims      │\n",
      "╞════════╪════════════════╪═══════════════╪═══════════════╪═══════════╡\n",
      "│ X      │ (360, 8, 8, 1) │ (90, 8, 8, 1) │ (50, 8, 8, 1) │ (8, 8, 1) │\n",
      "├────────┼────────────────┼───────────────┼───────────────┼───────────┤\n",
      "│ y      │ (360,)         │ (90,)         │ (50,)         │ (1,)      │\n",
      "╘════════╧════════════════╧═══════════════╧═══════════════╧═══════════╛\n",
      "\n",
      "╒══════════════╤═══════╤═══════╤════════╤═══════╤══════════════════════════╕\n",
      "│ Type         │   Min │   Max │   Mean │   Std │ Samples for each class   │\n",
      "╞══════════════╪═══════╪═══════╪════════╪═══════╪══════════════════════════╡\n",
      "│ Train Images │ -2.73 │ 20.76 │   0    │  1.03 │ [180, 180]               │\n",
      "├──────────────┼───────┼───────┼────────┼───────┼──────────────────────────┤\n",
      "│ Val Images   │ -1.81 │ 15    │  -0.01 │  0.88 │ [45, 45]                 │\n",
      "├──────────────┼───────┼───────┼────────┼───────┼──────────────────────────┤\n",
      "│ Test Images  │ -2.69 │ 53.39 │   0.07 │  1.98 │ [25, 25]                 │\n",
      "╘══════════════╧═══════╧═══════╧════════╧═══════╧══════════════════════════╛\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = ElectronPhoton(args)\n",
    "data.prepare_data()\n",
    "data.setup()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee393ddd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T04:46:20.867005Z",
     "start_time": "2022-07-28T04:46:20.805825Z"
    }
   },
   "outputs": [],
   "source": [
    "# LR Scheduler callback\n",
    "lr_scheduler_callback = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                          factor=0.1,\n",
    "                                          patience=5,\n",
    "                                          min_delta=0.0001,\n",
    "                                          min_lr=1e-6)\n",
    "callbacks = [lr_scheduler_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78cb493",
   "metadata": {},
   "source": [
    "## NQubit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "235a16a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T04:46:22.493984Z",
     "start_time": "2022-07-28T04:46:22.401702Z"
    }
   },
   "outputs": [],
   "source": [
    "import cirq\n",
    "import sympy as sp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NQubit:\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __single_qubit_rot(self, qubit, symbols, sparse):\n",
    "        if sparse:\n",
    "            return [cirq.Y(qubit)**(symbols)]\n",
    "        return [[\n",
    "            cirq.Z(qubit)**symbols[i],\n",
    "            cirq.Y(qubit)**symbols[i + 1],\n",
    "            cirq.Z(qubit)**symbols[i + 2]\n",
    "        ] for i in range(0, len(symbols), 3)]\n",
    "\n",
    "    def build(self, qubits, feature_map, n_layers, drc, sparse,\n",
    "              in_symbols=None,extras=None):\n",
    "\n",
    "        # Observables\n",
    "        Z = cirq.PauliString(cirq.Z(qubits[-1]))\n",
    "        I = cirq.PauliString(cirq.I(qubits[-1]))\n",
    "        observable = [-0.5 * Z + 0.5 * I]\n",
    "\n",
    "        circuit = cirq.Circuit()\n",
    "        for l in range(n_layers):\n",
    "            circuit += cirq.Circuit(\n",
    "                self.__single_qubit_rot(q, in_symbols[l, i], sparse)\n",
    "                for i, q in enumerate(qubits))\n",
    "\n",
    "            # Alternate CZ entangling circuit\n",
    "            if (l & 1):\n",
    "                circuit += [\n",
    "                    cirq.CZ(q0, q1)\n",
    "                    for q0, q1 in zip(qubits[1::2], qubits[2::2] + [qubits[0]])\n",
    "                ]\n",
    "\n",
    "            else:\n",
    "                circuit += [\n",
    "                    cirq.CZ(q0, q1)\n",
    "                    for q0, q1 in zip(qubits[0::2], qubits[1::2])\n",
    "                ]\n",
    "\n",
    "        return circuit, [], [], observable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b32050c",
   "metadata": {},
   "source": [
    "## QConv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3258c8ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T04:46:23.789767Z",
     "start_time": "2022-07-28T04:46:23.693562Z"
    }
   },
   "outputs": [],
   "source": [
    "class QConv2D(Layer):\n",
    "    \"\"\"\n",
    "    2D Quantum convolution layer (e.g. spatial convolution over images).\n",
    "    This layer creates a convolution kernel that is convolved \n",
    "    with the layer input to produce a tensor of outputs. Finally,\n",
    "    `activation` is applied to the outputs as well.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            filters=1,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            n_qubits=1,\n",
    "            n_layers=1,\n",
    "            sparse=False,\n",
    "            padding='valid',\n",
    "            activation='relu',\n",
    "            cluster_state=False,\n",
    "            fm_class='AngleMap',\n",
    "            ansatz_class='Chen',\n",
    "            observable=None,\n",
    "            drc=False,\n",
    "            extras = None,\n",
    "            name='QConv2D',\n",
    "    ):\n",
    "\n",
    "        super(QConv2D, self).__init__(name=name)\n",
    "\n",
    "        # Filters\n",
    "        if isinstance(filters, float):\n",
    "            filters = int(filters)\n",
    "        if filters is not None and filters <= 0:\n",
    "            raise ValueError('Invalid value for argument `filters`. '\n",
    "                             'Expected a strictly positive value. '\n",
    "                             f'Received filters={filters}.')\n",
    "        self.filters = filters\n",
    "\n",
    "        # Num layers\n",
    "        if isinstance(n_layers, float):\n",
    "            n_layers = int(n_layers)\n",
    "        if n_layers is not None and n_layers <= 0:\n",
    "            raise ValueError('Invalid value for argument `n_layers`. '\n",
    "                             'Expected a strictly positive value. '\n",
    "                             f'Received n_layers={n_layers}.')\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.observable = observable\n",
    "        self.kernel_size = normalize_tuple(kernel_size, 'kernel_size')\n",
    "        self.strides = normalize_tuple(strides, 'strides')\n",
    "        self.padding = normalize_padding(padding)\n",
    "        self.activation = Activation(activation)\n",
    "        self.cluster_state = cluster_state\n",
    "        self.fm_class = fm_class\n",
    "        self.ansatz_class = ansatz_class\n",
    "        self.drc = drc\n",
    "        self.n_qubits = n_qubits\n",
    "        self.sparse = sparse\n",
    "        self.extras = extras\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.iters, self.padding_constant = convolution_iters(\n",
    "            input_shape[1:3], self.kernel_size, self.strides, self.padding)\n",
    "        self.n_channels = input_shape[3]\n",
    "\n",
    "        self.conv_pqcs = [[(filter, channel)\n",
    "                           for channel in range(self.n_channels)]\n",
    "                          for filter in range(self.filters)]\n",
    "\n",
    "        if self.ansatz_class == 'NQubit':\n",
    "            for filter in range(self.filters):\n",
    "                for channel in range(self.n_channels):\n",
    "                    name = f\"{self.name}_{filter}_{channel}\"\n",
    "                    self.conv_pqcs[filter][channel] = NQubitPQC(\n",
    "                        self.n_qubits, self.cluster_state, self.observable,\n",
    "                        self.n_layers, self.sparse, self.extras, name)\n",
    "        else:\n",
    "            self.n_qubits = get_count_of_qubits(self.fm_class,\n",
    "                                                np.prod(self.kernel_size))\n",
    "            self.n_inputs = get_num_in_symbols(self.fm_class,\n",
    "                                               np.prod(self.kernel_size))\n",
    "\n",
    "            self.feature_map = _import_class(\n",
    "                f\"qml_hep_lhc.encodings.{self.fm_class}\")()\n",
    "            self.ansatz = _import_class(\n",
    "                f\"qml_hep_lhc.ansatzes.{self.ansatz_class}\")()\n",
    "\n",
    "            for filter in range(self.filters):\n",
    "                for channel in range(self.n_channels):\n",
    "                    name = f\"{self.name}_{filter}_{channel}\"\n",
    "                    self.conv_pqcs[filter][channel] = TwoLayerPQC(\n",
    "                        self.n_qubits, self.n_inputs, self.feature_map,\n",
    "                        self.ansatz, self.cluster_state, self.observable,\n",
    "                        self.n_layers, self.drc, name)\n",
    "\n",
    "    def _convolution(self, input_tensor, filter, channel):\n",
    "\n",
    "        s = self.strides\n",
    "        k = self.kernel_size\n",
    "\n",
    "        conv_out = []\n",
    "        for i in range(self.iters[0]):\n",
    "            for j in range(self.iters[1]):\n",
    "                x = input_tensor[:, i * s[0]:i * s[0] + k[0], j *\n",
    "                                 s[1]:j * s[1] + k[1]]\n",
    "                conv_out += [self.conv_pqcs[filter][channel](x)]\n",
    "\n",
    "        conv_out = Concatenate(axis=1)(conv_out)\n",
    "        conv_out = Reshape((self.iters[0], self.iters[1], 1))(conv_out)\n",
    "        return conv_out\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        input_tensor = pad(input_tensor, self.padding_constant)\n",
    "\n",
    "        if self.n_channels == 1:\n",
    "            conv_out = [\n",
    "                self._convolution(input_tensor[:, :, :, 0], filter, 0)\n",
    "                for filter in range(self.filters)\n",
    "            ]\n",
    "\n",
    "        else:\n",
    "            conv_out = [\n",
    "                Add()([\n",
    "                    self._convolution(input_tensor[:, :, :, c], filter, c)\n",
    "                    for c in range(self.n_channels)\n",
    "                ])\n",
    "                for filter in range(self.filters)\n",
    "            ]\n",
    "\n",
    "        conv_out = Concatenate(axis=-1)(conv_out)\n",
    "        return self.activation(conv_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12ad06b",
   "metadata": {},
   "source": [
    "## QCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecff8c6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T04:46:25.620365Z",
     "start_time": "2022-07-28T04:46:25.510427Z"
    }
   },
   "outputs": [],
   "source": [
    "class QCNN(BaseModel):\n",
    "    \"\"\"\n",
    "\tGeneral Quantum Convolutional Neural Network\n",
    "\t\"\"\"\n",
    "\n",
    "    def __init__(self, data_config, args=None, extras=None):\n",
    "        super(QCNN, self).__init__(args)\n",
    "        self.args = vars(args) if args is not None else {}\n",
    "\n",
    "        # Data config\n",
    "        self.input_dim = data_config[\"input_dims\"]\n",
    "        self.cluster_state = self.args.get(\"cluster_state\", False)\n",
    "        self.fm_class = self.args.get(\"feature_map\", None)\n",
    "        self.ansatz_class = self.args.get(\"ansatz\", None)\n",
    "        self.n_layers = self.args.get(\"n_layers\", 1)\n",
    "        self.n_qubits = self.args.get(\"n_qubits\", 1)\n",
    "        self.sparse = self.args.get(\"sparse\", False)\n",
    "\n",
    "        if self.fm_class is None:\n",
    "            self.fm_class = \"AngleMap\"\n",
    "        if self.ansatz_class is None:\n",
    "            self.ansatz_class = \"Chen\"\n",
    "\n",
    "        self.drc = self.args.get(\"drc\", False)\n",
    "\n",
    "        input_shape = [None] + list(self.input_dim)\n",
    "        \n",
    "        if extras is not None:\n",
    "            layerwise_extras = []\n",
    "            l = len(extras['trained'])\n",
    "            for i in range(l):\n",
    "                layerwise_extras.append({\n",
    "                    'first_half': extras['first_half'],\n",
    "                    'ps':extras['ps'],\n",
    "                    'trained': extras['trained'][i],\n",
    "                    'untrained': extras['untrained'][i]\n",
    "                })\n",
    "        else:\n",
    "            layerwise_extras = [None]*10\n",
    "\n",
    "        self.qconv2d_1 = QConv2D(\n",
    "            filters=1,\n",
    "            kernel_size=3,\n",
    "            strides=2,\n",
    "            n_qubits=self.n_qubits,\n",
    "            n_layers=self.n_layers,\n",
    "            sparse=self.sparse,\n",
    "            padding=\"same\",\n",
    "            cluster_state=self.cluster_state,\n",
    "            fm_class=self.fm_class,\n",
    "            ansatz_class=self.ansatz_class,\n",
    "            drc=self.drc,\n",
    "            extras = layerwise_extras[0],\n",
    "            name='qconv2d_1',\n",
    "        )\n",
    "\n",
    "        input_shape = self.qconv2d_1.compute_output_shape(input_shape)\n",
    "\n",
    "        self.qconv2d_2 = QConv2D(\n",
    "            filters=1,\n",
    "            kernel_size=3,\n",
    "            strides=2,\n",
    "            n_qubits=self.n_qubits,\n",
    "            n_layers=self.n_layers,\n",
    "            sparse=self.sparse,\n",
    "            padding=\"same\",\n",
    "            cluster_state=self.cluster_state,\n",
    "            fm_class=self.fm_class,\n",
    "            ansatz_class=self.ansatz_class,\n",
    "            drc=self.drc,\n",
    "            extras = layerwise_extras[1] ,\n",
    "            name='qconv2d_2',\n",
    "        )\n",
    "\n",
    "        input_shape = self.qconv2d_2.compute_output_shape(input_shape)\n",
    "\n",
    "        if self.ansatz_class == 'NQubit':\n",
    "            self.vqc = NQubitPQC(\n",
    "                self.n_qubits,\n",
    "                self.cluster_state,\n",
    "                None,\n",
    "                self.n_layers,\n",
    "                self.sparse,\n",
    "                layerwise_extras[2],\n",
    "            )\n",
    "        else:\n",
    "            if ((np.prod(input_shape[1:]) > 16) and\n",
    "                (self.fm_class != \"AmplitudeMap\")):\n",
    "                print(\n",
    "                    f\"Will use max pooling layer since n_qubits = {np.prod(input_shape[1:])} > 16\"\n",
    "                )\n",
    "                self.max_pool = MaxPool2D(pool_size=(2, 2))\n",
    "                input_shape = self.max_pool.compute_output_shape(input_shape)\n",
    "\n",
    "            if ((np.prod(input_shape[1:]) > 16) and\n",
    "                (self.fm_class != \"AmplitudeMap\")):\n",
    "                print(\n",
    "                    f\"Will use Amplitude Map since n_qubits = {np.prod(input_shape[1:])} > 16 even after max pooling\"\n",
    "                )\n",
    "                self.fm_class = \"AmplitudeMap\"\n",
    "\n",
    "            n_qubits = get_count_of_qubits(self.fm_class,\n",
    "                                           np.prod(input_shape[1:]))\n",
    "            n_inputs = get_num_in_symbols(self.fm_class,\n",
    "                                          np.prod(input_shape[1:]))\n",
    "\n",
    "            feature_map = _import_class(\n",
    "                f\"qml_hep_lhc.encodings.{self.fm_class}\")()\n",
    "            ansatz = _import_class(\n",
    "                f\"qml_hep_lhc.ansatzes.{self.ansatz_class}\")()\n",
    "\n",
    "            self.vqc = TwoLayerPQC(\n",
    "                n_qubits,\n",
    "                n_inputs,\n",
    "                feature_map,\n",
    "                ansatz,\n",
    "                self.cluster_state,\n",
    "                None,\n",
    "                self.n_layers,\n",
    "                self.drc,\n",
    "            )\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        x = self.qconv2d_1(input_tensor)\n",
    "        x = self.qconv2d_2(x)\n",
    "        if hasattr(self, \"max_pool\"):\n",
    "            x = self.max_pool(x)\n",
    "        x = Flatten()(x)\n",
    "        x = self.vqc(x)\n",
    "        return x\n",
    "\n",
    "    def build_graph(self):\n",
    "        x = Input(shape=self.input_dim)\n",
    "        return Model(inputs=[x],\n",
    "                     outputs=self.call(x),\n",
    "                     name=f\"QCNN-{self.fm_class}-{self.ansatz_class}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def add_to_argparse(parser):\n",
    "        parser.add_argument(\"--cluster-state\",\n",
    "                            action=\"store_true\",\n",
    "                            default=False)\n",
    "        parser.add_argument(\"--feature-map\", \"-fm\", type=str)\n",
    "        parser.add_argument(\"--ansatz\", type=str)\n",
    "        parser.add_argument(\"--n-layers\", type=int, default=1)\n",
    "        parser.add_argument(\"--drc\", action=\"store_true\", default=False)\n",
    "        parser.add_argument(\"--n-qubits\", type=int, default=1)\n",
    "        parser.add_argument(\"--sparse\", action=\"store_true\", default=False)\n",
    "        return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9711b5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T04:46:48.039471Z",
     "start_time": "2022-07-28T04:46:45.006837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Adam optimizer\n"
     ]
    }
   ],
   "source": [
    "model = QCNN(data.config(),args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50ed219f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T08:33:03.276246Z",
     "start_time": "2022-07-28T08:33:03.174390Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2966/2868459614.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtraining_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_layers_to_add\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_layer_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args.learning_rate = 0.1\n",
    "args.ansatz = 'NQubit'\n",
    "args.sparse = 1\n",
    "args.n_layers = 2\n",
    "args.batch_size = 64\n",
    "args.cluster_state = 1\n",
    "args.use_quantum = 1\n",
    "\n",
    "n_layers_to_add = 3 # keep it one only\n",
    "args.epochs = 1\n",
    "args.n_qubits = 6\n",
    "n_layer_steps = 3\n",
    "\n",
    "symbols = []\n",
    "layers = []\n",
    "symbol_layers = []\n",
    "weights = []\n",
    "\n",
    "training_history = []\n",
    "\n",
    "assert ((n_layers_to_add*n_layer_steps)&1) == 0\n",
    "\n",
    "model = QCNN(data.config(),args)\n",
    "print(model.build_graph().summary(expand_nested=True))\n",
    "random_weights = []\n",
    "for i, l in enumerate(model.layers):\n",
    "    w = model.layers[i].get_weights()\n",
    "    random_weights.append(w)\n",
    "\n",
    "args.n_layers = 0\n",
    "for layer_id in range(n_layer_steps):\n",
    "    print(\"\\nLayer:\", layer_id, '*'*100)\n",
    "    \n",
    "    args.n_layers += n_layers_to_add\n",
    "    model = QCNN(data.config(),args)\n",
    "    print(model.build_graph().summary(expand_nested=True))\n",
    "    \n",
    "    model.compile()\n",
    "    # set parameters to 0 for new layers\n",
    "    \n",
    "    if layer_id:\n",
    "        for i, _ in enumerate(model.layers):\n",
    "            res = []\n",
    "            for j, w in enumerate(weights[i]):\n",
    "                res.append(np.append(w,random_weights[i][j]).reshape(1,-1))\n",
    "            model.layers[i].set_weights(res)\n",
    "    \n",
    "    model.fit(data, callbacks)\n",
    "    \n",
    "    qnn_results = model.test(data, callbacks)\n",
    "    training_history.append(qnn_results)\n",
    "    \n",
    "    weights = []\n",
    "    for i, _ in enumerate(model.layers):\n",
    "        weights.append(model.layers[i].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d05779e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T07:20:40.113566Z",
     "start_time": "2022-07-28T07:20:39.823678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4fb0c86a90>,\n",
       " <matplotlib.lines.Line2D at 0x7f4fb0c881d0>,\n",
       " <matplotlib.lines.Line2D at 0x7f4fb0c86950>,\n",
       " <matplotlib.lines.Line2D at 0x7f4fb0c86390>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2030cb7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T07:20:41.671476Z",
     "start_time": "2022-07-28T07:20:41.553566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 432)\n",
      "(1, 48)\n",
      "(1, 432)\n",
      "(1, 48)\n",
      "(1, 192)\n",
      "(1, 48)\n"
     ]
    }
   ],
   "source": [
    "for w in weights:\n",
    "    for j in w:\n",
    "        print(j.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e9cbb",
   "metadata": {},
   "source": [
    "## NQubitPQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc96ab4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T07:20:43.373510Z",
     "start_time": "2022-07-28T07:20:43.257886Z"
    }
   },
   "outputs": [],
   "source": [
    "class NQubitPQC(Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_qubits,\n",
    "                 cluster_state=False,\n",
    "                 observable=None,\n",
    "                 n_layers=1,\n",
    "                 sparse=False,\n",
    "                 extras = None,\n",
    "                 name='NQubitPQC'):\n",
    "\n",
    "        super(NQubitPQC, self).__init__(name=name)\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "        self.n_qubits = n_qubits\n",
    "        self.cluster_state = cluster_state\n",
    "        self.observable = observable\n",
    "        self.sparse = sparse\n",
    "        self.activation = 'tanh'\n",
    "\n",
    "        # Prepare qubits\n",
    "        self.qubits = cirq.GridQubit.rect(1, self.n_qubits)\n",
    "        self.extras = extras\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.n_inputs = np.prod(input_shape[1:])\n",
    "\n",
    "        # Make n_inputs a multiple of 3 greater than or equal to n_inputs\n",
    "        if self.sparse is False:\n",
    "            if self.n_inputs % 3 != 0:\n",
    "                self.n_inputs += (3 - (self.n_inputs % 3))\n",
    "\n",
    "        circuit = cirq.Circuit()\n",
    "\n",
    "        if self.cluster_state:\n",
    "            circuit += cluster_state_circuit(self.qubits)\n",
    "\n",
    "        # Sympy symbols for (wx + b) input\n",
    "        self.num_in_symbols = self.n_inputs * self.n_layers * self.n_qubits\n",
    "        in_shape = (self.n_layers, self.n_qubits, self.n_inputs)\n",
    "        num_weights = self.num_in_symbols\n",
    "        num_biases = self.num_in_symbols\n",
    "\n",
    "        if self.sparse:\n",
    "            self.num_in_symbols = self.n_layers * self.n_qubits\n",
    "            in_shape = (self.n_layers, self.n_qubits)\n",
    "            num_biases = self.num_in_symbols\n",
    "                \n",
    "        in_symbols = sp.symbols(f'w0:{self.num_in_symbols}')\n",
    "        self.in_symbols = np.asarray(in_symbols).reshape(in_shape)\n",
    "            \n",
    "        \n",
    "        var_circuit, _, _, obs = NQubit().build(self.qubits, None,\n",
    "                                                self.n_layers, True,\n",
    "                                                self.sparse, self.in_symbols)\n",
    "\n",
    "        if self.observable is None:\n",
    "            self.observable = obs\n",
    "        circuit += var_circuit\n",
    "\n",
    "        self.in_symbols = list(self.in_symbols.flat)\n",
    "\n",
    "        # Initalize variational angles\n",
    "        w_init = random_uniform_initializer(minval=-1, maxval=1)\n",
    "        b_init = random_uniform_initializer(minval=-0.1, maxval=0.1)\n",
    "        \n",
    "        # During set_weights The weight values should be passed in the order they are created by the layer.\n",
    "        if self.sparse and self.extras is not None:\n",
    "            if self.extras['first_half']:\n",
    "                num_t_weights = (self.n_inputs * self.n_qubits * self.extras['ps'])\n",
    "                num_t_biases =  self.extras['ps'] * self.n_qubits\n",
    "            else:\n",
    "                num_t_weights = (self.n_inputs * self.n_qubits * (self.n_layers - self.extras['ps']))\n",
    "                num_t_biases =  (self.n_layers - self.extras['ps']) * self.n_qubits\n",
    "                \n",
    "            self.qweights = Variable(initial_value=w_init(shape=(1, num_t_weights),\n",
    "                                                          dtype=\"float32\"),\n",
    "                                     trainable=True,\n",
    "                                     name=self.name + \"_qweights\")\n",
    "            self.qbiases = Variable(initial_value=b_init(shape=(1, num_t_biases),\n",
    "                                                         dtype=\"float32\"),\n",
    "                                    trainable=True,\n",
    "                                    name=self.name + \"_qbiases\")\n",
    "            \n",
    "            self.qntweights = Variable(initial_value= np.array(self.extras['untrained'][0]),\n",
    "                                     trainable=False,\n",
    "                                     name=self.name + \"_qweights\")\n",
    "            \n",
    "            self.qntbiases = Variable(initial_value= np.array(self.extras['untrained'][1]),\n",
    "                                     trainable=False,\n",
    "                                     name=self.name + \"_qweights\")\n",
    "        else:\n",
    "            self.qweights = Variable(initial_value=w_init(shape=(1, num_weights),dtype=\"float32\"),\n",
    "                                     trainable=True,\n",
    "                                     name=self.name + \"_qweights\")\n",
    "            self.qbiases = Variable(initial_value=b_init(shape=(1, num_biases),dtype=\"float32\"),\n",
    "                                    trainable=True,\n",
    "                                    name=self.name + \"_qbiases\")\n",
    "            \n",
    "        # Align Left\n",
    "        circuit = cirq.align_left(circuit)\n",
    "        \n",
    "        print()\n",
    "        print(circuit)\n",
    "        print()\n",
    "        \n",
    "        # Define explicit symbol order\n",
    "        symbols = [str(symb) for symb in self.in_symbols]\n",
    "        self.indices = constant([symbols.index(a) for a in sorted(symbols)])\n",
    "\n",
    "        # Define computation layer\n",
    "        self.empty_circuit = tfq.convert_to_tensor([cirq.Circuit()])\n",
    "        self.computation_layer = tfq.layers.ControlledPQC(\n",
    "            circuit, self.observable)\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        batch_dim = shape(input_tensor)[0]\n",
    "        x = Flatten()(input_tensor)\n",
    "\n",
    "        # Pad input_tensor if not a multiple of 3\n",
    "        if self.sparse is False:\n",
    "            if x.shape[1] % 3 != 0:\n",
    "                x = pad(x, [[0, 0], [0, 3 - x.shape[1] % 3]])\n",
    "\n",
    "        tiled_up_circuits = repeat(self.empty_circuit,\n",
    "                                   repeats=batch_dim,\n",
    "                                   name=self.name + \"_tiled_up_circuits\")\n",
    "        \n",
    "        # Multiply by weights\n",
    "        if self.sparse and self.extras is not None:\n",
    "            if self.extras['first_half']:\n",
    "                tiled_up_inputx = tile(x, multiples=[1, self.extras['ps'] * self.n_qubits])\n",
    "                tiled_up_inputy = tile(x, multiples=[1, (self.n_layers-self.extras['ps']) * self.n_qubits])\n",
    "                \n",
    "                tiled_up_inputx = multiply(tiled_up_inputx,\n",
    "                                   self.qweights,\n",
    "                                   name=self.name + \"_tiled_up_inputx_qweights\")\n",
    "                \n",
    "                tiled_up_inputy = multiply(tiled_up_inputy,\n",
    "                                   self.qntweights,\n",
    "                                   name=self.name + \"_tiled_up_inputy_qntweights\")\n",
    "                \n",
    "            else:\n",
    "                tiled_up_inputx = tile(x, multiples=[1, (self.n_layers-self.extras['ps']) * self.n_qubits])\n",
    "                tiled_up_inputy = tile(x, multiples=[1, self.extras['ps'] * self.n_qubits])\n",
    "                \n",
    "                tiled_up_inputx = multiply(tiled_up_inputx,\n",
    "                                       self.qntweights,\n",
    "                                       name=self.name + \"_tiled_up_inputx_qntweights\")\n",
    "            \n",
    "                tiled_up_inputy = multiply(tiled_up_inputy,\n",
    "                                       self.qweights,\n",
    "                                       name=self.name + \"_tiled_up_inputy_qweights\")\n",
    "            \n",
    "        else:\n",
    "            tiled_up_inputs = tile(x, multiples=[1, self.n_layers * self.n_qubits])\n",
    "            tiled_up_inputs = multiply(tiled_up_inputs,\n",
    "                                   self.qweights,\n",
    "                                   name=self.name + \"_tiled_up_inputs_qweights\")\n",
    "\n",
    "        if self.sparse is False:\n",
    "            # Add biases\n",
    "            tiled_up_inputs = add(tiled_up_inputs,\n",
    "                                  self.qbiases,\n",
    "                                  name=self.name +\n",
    "                                  \"_tiled_up_inputs_qweights_qbiases\")\n",
    "        else:\n",
    "            if self.extras is None:\n",
    "                # Reshape to (batch,n_layers*n_qubits,n_inputs)\n",
    "                tile_up_inputs = tf.reshape(\n",
    "                    tiled_up_inputs,\n",
    "                    [batch_dim, self.n_layers * self.n_qubits, self.n_inputs],\n",
    "                    name=self.name + \"_reshaped_inputs\")\n",
    "\n",
    "                # Sum over each layer and qubit (w1*x1 + w2*x2 + ...)\n",
    "                # The new shape is (batch, n_layers*n_qubits)\n",
    "                tiled_up_inputs = tf.reduce_sum(tile_up_inputs,\n",
    "                                                axis=-1,\n",
    "                                                name=self.name +\n",
    "                                                \"_tiled_up_inputs_reduced_sum\")\n",
    "\n",
    "                # Add biases\n",
    "                tiled_up_inputs = add(tiled_up_inputs,\n",
    "                                      self.qbiases,\n",
    "                                      name=self.name +\n",
    "                                      \"_tiled_up_inputs_qweights_qbiases\")\n",
    "            else:\n",
    "                if self.extras['first_half']:\n",
    "                    # Reshape to (batch,self.extras['ps']*n_qubits,n_inputs)\n",
    "                    tile_up_inputx = tf.reshape(\n",
    "                        tiled_up_inputx,\n",
    "                        [batch_dim, self.extras['ps'] * self.n_qubits, self.n_inputs],\n",
    "                        name=self.name + \"_reshaped_inputx\")\n",
    "                    \n",
    "                    # Sum over each layer and qubit (w1*x1 + w2*x2 + ...)\n",
    "                    # The new shape is (batch, self.extras['ps']*n_qubits)\n",
    "                    tiled_up_inputx = tf.reduce_sum(tile_up_inputx,\n",
    "                                                    axis=-1,\n",
    "                                                    name=self.name +\n",
    "                                                    \"_tiled_up_inputx_reduced_sum\")\n",
    "                    # Add biases\n",
    "                    tiled_up_inputx = add(tiled_up_inputx,\n",
    "                                          self.qbiases,\n",
    "                                          name=self.name +\n",
    "                                          \"_tiled_up_inputx_qweights_qbiases\")\n",
    "                    \n",
    "                    # Reshape to (batch,(self.n_layers-self.extras['ps'])*n_qubits,n_inputs)\n",
    "                    tile_up_inputy = tf.reshape(\n",
    "                        tiled_up_inputy,\n",
    "                        [batch_dim, (self.n_layers - self.extras['ps']) * self.n_qubits, self.n_inputs],\n",
    "                        name=self.name + \"_reshaped_inputy\")\n",
    "                    \n",
    "                    # Sum over each layer and qubit (w1*x1 + w2*x2 + ...)\n",
    "                    # The new shape is (batch, (self.n_layers-self.extras['ps'])*n_qubits)\n",
    "                    tiled_up_inputy = tf.reduce_sum(tile_up_inputy,\n",
    "                                                    axis=-1,\n",
    "                                                    name=self.name +\n",
    "                                                    \"_tiled_up_inputy_reduced_sum\")\n",
    "                    # Add biases\n",
    "                    tiled_up_inputy = add(tiled_up_inputy,\n",
    "                                          self.qntbiases,\n",
    "                                          name=self.name +\n",
    "                                          \"_tiled_up_inputx_qntweights_qntbiases\")\n",
    "                else:\n",
    "                    # Reshape to (batch,self.extras['ps']*n_qubits,n_inputs)\n",
    "                    tile_up_inputx = tf.reshape(\n",
    "                        tiled_up_inputx,\n",
    "                        [batch_dim, (self.n_layers - self.extras['ps']) * self.n_qubits, self.n_inputs],\n",
    "                        name=self.name + \"_reshaped_inputx\")\n",
    "                    \n",
    "                    # Sum over each layer and qubit (w1*x1 + w2*x2 + ...)\n",
    "                    # The new shape is (batch, self.extras['ps']*n_qubits)\n",
    "                    tiled_up_inputx = tf.reduce_sum(tile_up_inputx,\n",
    "                                                    axis=-1,\n",
    "                                                    name=self.name +\n",
    "                                                    \"_tiled_up_inputx_reduced_sum\")\n",
    "                    # Add biases\n",
    "                    tiled_up_inputx = add(tiled_up_inputx,\n",
    "                                          self.qntbiases,\n",
    "                                          name=self.name +\n",
    "                                          \"_tiled_up_inputx_qntweights_qntbiases\")\n",
    "                    \n",
    "                    # Reshape to (batch,(self.n_layers-self.extras['ps'])*n_qubits,n_inputs)\n",
    "                    tile_up_inputy = tf.reshape(\n",
    "                        tiled_up_inputy,\n",
    "                        [batch_dim, self.extras['ps'] * self.n_qubits, self.n_inputs],\n",
    "                        name=self.name + \"_reshaped_inputy\")\n",
    "                    \n",
    "                    # Sum over each layer and qubit (w1*x1 + w2*x2 + ...)\n",
    "                    # The new shape is (batch, (self.n_layers-self.extras['ps'])*n_qubits)\n",
    "                    tiled_up_inputy = tf.reduce_sum(tile_up_inputy,\n",
    "                                                    axis=-1,\n",
    "                                                    name=self.name +\n",
    "                                                    \"_tiled_up_inputy_reduced_sum\")\n",
    "                    # Add biases\n",
    "                    tiled_up_inputy = add(tiled_up_inputy,\n",
    "                                          self.qbiases,\n",
    "                                          name=self.name +\n",
    "                                          \"_tiled_up_inputx_qweights_qbiases\")\n",
    "                \n",
    "                tiled_up_inputs = tf.concat([tiled_up_inputx,tiled_up_inputy], 1)\n",
    "            \n",
    "        tiled_up_inputs = Activation(\n",
    "            self.activation)(tiled_up_inputs) * (np.pi / 2)\n",
    "\n",
    "        joined_vars = gather(tiled_up_inputs,\n",
    "                             self.indices,\n",
    "                             axis=1,\n",
    "                             name=self.name + \"_joined_vars\")\n",
    "        return tf.clip_by_value(\n",
    "            self.computation_layer([tiled_up_circuits, joined_vars]), 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd2dac4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T07:21:46.681681Z",
     "start_time": "2022-07-28T07:20:44.670289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sweep over partitions\n",
      "\n",
      "\n",
      "Sweep 1, partition 1\n",
      "\n",
      "Using Adam optimizer\n",
      "\n",
      "                                  ┌──┐                       ┌──┐                       ┌──┐                       ┌──┐\n",
      "(0, 0): ───H───Y^w0───@───Y^w6──────@────Y^w12───@───Y^w18─────@────Y^w24───@───Y^w30─────@────Y^w36───@───Y^w42─────@────\n",
      "                      │             │            │             │            │             │            │             │\n",
      "(0, 1): ───H───Y^w1───@───Y^w7─────@┼────Y^w13───@───Y^w19────@┼────Y^w25───@───Y^w31────@┼────Y^w37───@───Y^w43────@┼────\n",
      "                                   ││                         ││                         ││                         ││\n",
      "(0, 2): ───H───Y^w2───@───Y^w8─────@┼────Y^w14───@───Y^w20────@┼────Y^w26───@───Y^w32────@┼────Y^w38───@───Y^w44────@┼────\n",
      "                      │             │            │             │            │             │            │             │\n",
      "(0, 3): ───H───Y^w3───@───Y^w9─────@┼────Y^w15───@───Y^w21────@┼────Y^w27───@───Y^w33────@┼────Y^w39───@───Y^w45────@┼────\n",
      "                                   ││                         ││                         ││                         ││\n",
      "(0, 4): ───H───Y^w4───@───Y^w10────@┼────Y^w16───@───Y^w22────@┼────Y^w28───@───Y^w34────@┼────Y^w40───@───Y^w46────@┼────\n",
      "                      │             │            │             │            │             │            │             │\n",
      "(0, 5): ───H───Y^w5───@───Y^w11─────@────Y^w17───@───Y^w23─────@────Y^w29───@───Y^w35─────@────Y^w41───@───Y^w47─────@────\n",
      "                                  └──┘                       └──┘                       └──┘                       └──┘\n",
      "\n",
      "\n",
      "                                  ┌──┐                       ┌──┐                       ┌──┐                       ┌──┐\n",
      "(0, 0): ───H───Y^w0───@───Y^w6──────@────Y^w12───@───Y^w18─────@────Y^w24───@───Y^w30─────@────Y^w36───@───Y^w42─────@────\n",
      "                      │             │            │             │            │             │            │             │\n",
      "(0, 1): ───H───Y^w1───@───Y^w7─────@┼────Y^w13───@───Y^w19────@┼────Y^w25───@───Y^w31────@┼────Y^w37───@───Y^w43────@┼────\n",
      "                                   ││                         ││                         ││                         ││\n",
      "(0, 2): ───H───Y^w2───@───Y^w8─────@┼────Y^w14───@───Y^w20────@┼────Y^w26───@───Y^w32────@┼────Y^w38───@───Y^w44────@┼────\n",
      "                      │             │            │             │            │             │            │             │\n",
      "(0, 3): ───H───Y^w3───@───Y^w9─────@┼────Y^w15───@───Y^w21────@┼────Y^w27───@───Y^w33────@┼────Y^w39───@───Y^w45────@┼────\n",
      "                                   ││                         ││                         ││                         ││\n",
      "(0, 4): ───H───Y^w4───@───Y^w10────@┼────Y^w16───@───Y^w22────@┼────Y^w28───@───Y^w34────@┼────Y^w40───@───Y^w46────@┼────\n",
      "                      │             │            │             │            │             │            │             │\n",
      "(0, 5): ───H───Y^w5───@───Y^w11─────@────Y^w17───@───Y^w23─────@────Y^w29───@───Y^w35─────@────Y^w41───@───Y^w47─────@────\n",
      "                                  └──┘                       └──┘                       └──┘                       └──┘\n",
      "\n",
      "\n",
      "                                  ┌──┐                       ┌──┐                       ┌──┐                       ┌──┐\n",
      "(0, 0): ───H───Y^w0───@───Y^w6──────@────Y^w12───@───Y^w18─────@────Y^w24───@───Y^w30─────@────Y^w36───@───Y^w42─────@────\n",
      "                      │             │            │             │            │             │            │             │\n",
      "(0, 1): ───H───Y^w1───@───Y^w7─────@┼────Y^w13───@───Y^w19────@┼────Y^w25───@───Y^w31────@┼────Y^w37───@───Y^w43────@┼────\n",
      "                                   ││                         ││                         ││                         ││\n",
      "(0, 2): ───H───Y^w2───@───Y^w8─────@┼────Y^w14───@───Y^w20────@┼────Y^w26───@───Y^w32────@┼────Y^w38───@───Y^w44────@┼────\n",
      "                      │             │            │             │            │             │            │             │\n",
      "(0, 3): ───H───Y^w3───@───Y^w9─────@┼────Y^w15───@───Y^w21────@┼────Y^w27───@───Y^w33────@┼────Y^w39───@───Y^w45────@┼────\n",
      "                                   ││                         ││                         ││                         ││\n",
      "(0, 4): ───H───Y^w4───@───Y^w10────@┼────Y^w16───@───Y^w22────@┼────Y^w28───@───Y^w34────@┼────Y^w40───@───Y^w46────@┼────\n",
      "                      │             │            │             │            │             │            │             │\n",
      "(0, 5): ───H───Y^w5───@───Y^w11─────@────Y^w17───@───Y^w23─────@────Y^w29───@───Y^w35─────@────Y^w41───@───Y^w47─────@────\n",
      "                                  └──┘                       └──┘                       └──┘                       └──┘\n",
      "\n",
      "Model: \"QCNN-AngleMap-NQubit\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_40 (InputLayer)       [(None, 8, 8, 1)]         0         \n",
      "                                                                 \n",
      " qconv2d_1 (QConv2D)         (None, 4, 4, 1)           480       \n",
      "                                                                 \n",
      " qconv2d_2 (QConv2D)         (None, 2, 2, 1)           480       \n",
      "                                                                 \n",
      " flatten_39 (Flatten)        (None, 4)                 0         \n",
      "                                                                 \n",
      " NQubitPQC (NQubitPQC)       (None, 1)                 240       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,200\n",
      "Trainable params: 600\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "3/3 [==============================] - 27s 6s/step - loss: 0.2750 - auc_42: 0.4506 - accuracy: 0.4306 - val_loss: 0.2889 - val_auc_42: 0.4146 - val_accuracy: 0.4333 - lr: 0.1000\n",
      "2\n",
      "(1, 216)\n",
      "(1, 24)\n",
      "2\n",
      "(1, 216)\n",
      "(1, 24)\n",
      "2\n",
      "(1, 96)\n",
      "(1, 24)\n",
      "1/1 [==============================] - 1s 880ms/step - loss: 0.3003 - auc_42: 0.3920 - accuracy: 0.5000\n",
      "\n",
      "Sweep 1, partition 2\n",
      "\n",
      "Using Adam optimizer\n",
      "\n",
      "                                  ┌──┐                       ┌──┐                       ┌──┐                       ┌──┐\n",
      "(0, 0): ───H───Y^w0───@───Y^w6──────@────Y^w12───@───Y^w18─────@────Y^w24───@───Y^w30─────@────Y^w36───@───Y^w42─────@────\n",
      "                      │             │            │             │            │             │            │             │\n",
      "(0, 1): ───H───Y^w1───@───Y^w7─────@┼────Y^w13───@───Y^w19────@┼────Y^w25───@───Y^w31────@┼────Y^w37───@───Y^w43────@┼────\n",
      "                                   ││                         ││                         ││                         ││\n",
      "(0, 2): ───H───Y^w2───@───Y^w8─────@┼────Y^w14───@───Y^w20────@┼────Y^w26───@───Y^w32────@┼────Y^w38───@───Y^w44────@┼────\n",
      "                      │             │            │             │            │             │            │             │\n",
      "(0, 3): ───H───Y^w3───@───Y^w9─────@┼────Y^w15───@───Y^w21────@┼────Y^w27───@───Y^w33────@┼────Y^w39───@───Y^w45────@┼────\n",
      "                                   ││                         ││                         ││                         ││\n",
      "(0, 4): ───H───Y^w4───@───Y^w10────@┼────Y^w16───@───Y^w22────@┼────Y^w28───@───Y^w34────@┼────Y^w40───@───Y^w46────@┼────\n",
      "                      │             │            │             │            │             │            │             │\n",
      "(0, 5): ───H───Y^w5───@───Y^w11─────@────Y^w17───@───Y^w23─────@────Y^w29───@───Y^w35─────@────Y^w41───@───Y^w47─────@────\n",
      "                                  └──┘                       └──┘                       └──┘                       └──┘\n",
      "\n",
      "\n",
      "                                  ┌──┐                       ┌──┐                       ┌──┐                       ┌──┐\n",
      "(0, 0): ───H───Y^w0───@───Y^w6──────@────Y^w12───@───Y^w18─────@────Y^w24───@───Y^w30─────@────Y^w36───@───Y^w42─────@────\n",
      "                      │             │            │             │            │             │            │             │\n",
      "(0, 1): ───H───Y^w1───@───Y^w7─────@┼────Y^w13───@───Y^w19────@┼────Y^w25───@───Y^w31────@┼────Y^w37───@───Y^w43────@┼────\n",
      "                                   ││                         ││                         ││                         ││\n",
      "(0, 2): ───H───Y^w2───@───Y^w8─────@┼────Y^w14───@───Y^w20────@┼────Y^w26───@───Y^w32────@┼────Y^w38───@───Y^w44────@┼────\n",
      "                      │             │            │             │            │             │            │             │\n",
      "(0, 3): ───H───Y^w3───@───Y^w9─────@┼────Y^w15───@───Y^w21────@┼────Y^w27───@───Y^w33────@┼────Y^w39───@───Y^w45────@┼────\n",
      "                                   ││                         ││                         ││                         ││\n",
      "(0, 4): ───H───Y^w4───@───Y^w10────@┼────Y^w16───@───Y^w22────@┼────Y^w28───@───Y^w34────@┼────Y^w40───@───Y^w46────@┼────\n",
      "                      │             │            │             │            │             │            │             │\n",
      "(0, 5): ───H───Y^w5───@───Y^w11─────@────Y^w17───@───Y^w23─────@────Y^w29───@───Y^w35─────@────Y^w41───@───Y^w47─────@────\n",
      "                                  └──┘                       └──┘                       └──┘                       └──┘\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                  ┌──┐                       ┌──┐                       ┌──┐                       ┌──┐\n",
      "(0, 0): ───H───Y^w0───@───Y^w6──────@────Y^w12───@───Y^w18─────@────Y^w24───@───Y^w30─────@────Y^w36───@───Y^w42─────@────\n",
      "                      │             │            │             │            │             │            │             │\n",
      "(0, 1): ───H───Y^w1───@───Y^w7─────@┼────Y^w13───@───Y^w19────@┼────Y^w25───@───Y^w31────@┼────Y^w37───@───Y^w43────@┼────\n",
      "                                   ││                         ││                         ││                         ││\n",
      "(0, 2): ───H───Y^w2───@───Y^w8─────@┼────Y^w14───@───Y^w20────@┼────Y^w26───@───Y^w32────@┼────Y^w38───@───Y^w44────@┼────\n",
      "                      │             │            │             │            │             │            │             │\n",
      "(0, 3): ───H───Y^w3───@───Y^w9─────@┼────Y^w15───@───Y^w21────@┼────Y^w27───@───Y^w33────@┼────Y^w39───@───Y^w45────@┼────\n",
      "                                   ││                         ││                         ││                         ││\n",
      "(0, 4): ───H───Y^w4───@───Y^w10────@┼────Y^w16───@───Y^w22────@┼────Y^w28───@───Y^w34────@┼────Y^w40───@───Y^w46────@┼────\n",
      "                      │             │            │             │            │             │            │             │\n",
      "(0, 5): ───H───Y^w5───@───Y^w11─────@────Y^w17───@───Y^w23─────@────Y^w29───@───Y^w35─────@────Y^w41───@───Y^w47─────@────\n",
      "                                  └──┘                       └──┘                       └──┘                       └──┘\n",
      "\n",
      "Model: \"QCNN-AngleMap-NQubit\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_41 (InputLayer)       [(None, 8, 8, 1)]         0         \n",
      "                                                                 \n",
      " qconv2d_1 (QConv2D)         (None, 4, 4, 1)           480       \n",
      "                                                                 \n",
      " qconv2d_2 (QConv2D)         (None, 2, 2, 1)           480       \n",
      "                                                                 \n",
      " flatten_40 (Flatten)        (None, 4)                 0         \n",
      "                                                                 \n",
      " NQubitPQC (NQubitPQC)       (None, 1)                 240       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,200\n",
      "Trainable params: 600\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "3/3 [==============================] - 26s 5s/step - loss: 0.2679 - auc_43: 0.4878 - accuracy: 0.4889 - val_loss: 0.2481 - val_auc_43: 0.5667 - val_accuracy: 0.5667 - lr: 0.1000\n",
      "2\n",
      "(1, 216)\n",
      "(1, 24)\n",
      "2\n",
      "(1, 216)\n",
      "(1, 24)\n",
      "2\n",
      "(1, 96)\n",
      "(1, 24)\n",
      "1/1 [==============================] - 1s 870ms/step - loss: 0.2808 - auc_43: 0.3736 - accuracy: 0.4200\n"
     ]
    }
   ],
   "source": [
    "final_num_layers = n_layer_steps*n_layers_to_add\n",
    "n_sweeps = 1\n",
    "partition_percentage = 0.5\n",
    "partition_size = int(n_layer_steps*n_layers_to_add*partition_percentage)\n",
    "args.n_layers = final_num_layers\n",
    "\n",
    "partition_weights = {\n",
    "    'p1': [],\n",
    "    'p2': []\n",
    "}\n",
    "\n",
    "for w in weights:\n",
    "    res_p1 = []\n",
    "    res_p2 = []\n",
    "    for j in w:\n",
    "        partition = int(j.shape[1]*partition_percentage)\n",
    "        res_p1.append(j[:,:partition].reshape(1,-1))\n",
    "        res_p2.append(j[:,partition:].reshape(1,-1))\n",
    "    partition_weights['p1'].append(res_p1)\n",
    "    partition_weights['p2'].append(res_p2)\n",
    "        \n",
    "def create_and_train_partition(extras):\n",
    "    model = QCNN(data.config(),args, extras)\n",
    "    model.compile()\n",
    "    print(model.build_graph().summary(expand_nested=True))\n",
    "    \n",
    "    for i, _ in enumerate(model.layers):\n",
    "        model.layers[i].set_weights([\n",
    "            extras['trained'][i][0],\n",
    "            extras['trained'][i][1],\n",
    "            extras['untrained'][i][0],\n",
    "            extras['untrained'][i][1]\n",
    "        ])\n",
    "            \n",
    "    model.fit(data, callbacks)\n",
    "    \n",
    "    part_weights = []\n",
    "    for i, _ in enumerate(model.layers):\n",
    "        part_weights.append(model.layers[i].get_weights()[:2])\n",
    "        \n",
    "    for w in part_weights:\n",
    "        print(len(w))\n",
    "        for j in w:\n",
    "            print(j.shape)\n",
    "    \n",
    "    qnn_results = model.test(data, callbacks)\n",
    "    training_history.append(qnn_results)\n",
    "\n",
    "    return part_weights\n",
    "\n",
    "print(\"\\nSweep over partitions\\n\")\n",
    "for sweep in range(n_sweeps):\n",
    "    # configure and train first partition\n",
    "    print(\"\\nSweep {}, partition 1\\n\".format(sweep+1))\n",
    "\n",
    "    extras= {\n",
    "        'first_half': True,\n",
    "        'ps':partition_size,\n",
    "        'trained': partition_weights['p1'],\n",
    "        'untrained': partition_weights['p2']\n",
    "    }\n",
    "    \n",
    "    part_weights = create_and_train_partition(extras)\n",
    "    partition_weights['p1'] = part_weights\n",
    "\n",
    "    # configure and train second partition\n",
    "    print(\"\\nSweep {}, partition 2\\n\".format(sweep+1))\n",
    "    \n",
    "    extras= {\n",
    "        'first_half': False,\n",
    "        'ps':partition_size,\n",
    "        'trained': partition_weights['p2'],\n",
    "        'untrained': partition_weights['p1']\n",
    "    }\n",
    "\n",
    "    part_weights = create_and_train_partition(extras)\n",
    "    partition_weights['p2'] = part_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "edf2730c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T07:21:46.950691Z",
     "start_time": "2022-07-28T07:21:46.685229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4f212dcf10>,\n",
       " <matplotlib.lines.Line2D at 0x7f4f21337b10>,\n",
       " <matplotlib.lines.Line2D at 0x7f4f42bd8150>,\n",
       " <matplotlib.lines.Line2D at 0x7f4f42bd8250>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d69b4c1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T08:47:05.551583Z",
     "start_time": "2022-07-27T08:47:05.471033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[72, 8], [72, 8], [32, 8]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_partition_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875205d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qenv)",
   "language": "python",
   "name": "qenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
