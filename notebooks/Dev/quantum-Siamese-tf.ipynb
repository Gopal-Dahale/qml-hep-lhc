{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f3a3d5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-01T10:18:35.743810Z",
     "start_time": "2022-10-01T10:18:30.492971Z"
    }
   },
   "outputs": [],
   "source": [
    "from importlib.util import find_spec\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "if find_spec(\"qml_hep_lhc\") is None:\n",
    "    import sys\n",
    "    sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0c44395",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-01T10:19:50.548653Z",
     "start_time": "2022-10-01T10:18:37.620406Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-01 15:48:43.367654: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-01 15:48:43.367742: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-01 15:49:49.506184: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-10-01 15:49:49.506276: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (bhagvada): /proc/driver/nvidia/version does not exist\n",
      "2022-10-01 15:49:49.531550: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from qml_hep_lhc.data import ElectronPhoton, MNIST, QuarkGluon\n",
    "from qml_hep_lhc.models import QCNNHybrid\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import argparse\n",
    "import numpy as np\n",
    "from qml_hep_lhc.data.utils import tf_ds_to_numpy, create_tf_ds\n",
    "from qml_hep_lhc.layers import QConv2D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2370ee1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-01T10:24:33.230536Z",
     "start_time": "2022-10-01T10:24:33.147809Z"
    }
   },
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n",
    "\n",
    "# Data\n",
    "args.center_crop = 0.2\n",
    "# args.resize = [8,8]\n",
    "# args.normalize = 1\n",
    "# args.binary_data = [0,1]\n",
    "args.batch_size = 128\n",
    "args.validation_split = 0.05\n",
    "args.dataset_type = '3'\n",
    "# args.labels_to_categorical = 1\n",
    "args.opt = 'Ranger'\n",
    "\n",
    "# Base Model\n",
    "args.learning_rate = 1e-3\n",
    "args.epochs = 50\n",
    "\n",
    "# Quantum CNN Parameters\n",
    "args.n_qubits = 1\n",
    "args.n_layers = 1\n",
    "args.ansatz = \"NQubit\"\n",
    "args.sparse = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ef42096",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-01T10:26:29.033913Z",
     "start_time": "2022-10-01T10:24:33.663760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center cropping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-01 15:54:52.540237: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1638400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center cropping...\n",
      "\n",
      "Dataset :Electron Photon 3\n",
      "╒════════╤═══════════════════╤══════════════════╤══════════════════╤═══════════╕\n",
      "│ Data   │ Train size        │ Val size         │ Test size        │ Dims      │\n",
      "╞════════╪═══════════════════╪══════════════════╪══════════════════╪═══════════╡\n",
      "│ X      │ (380000, 8, 8, 1) │ (20000, 8, 8, 1) │ (98000, 8, 8, 1) │ (8, 8, 1) │\n",
      "├────────┼───────────────────┼──────────────────┼──────────────────┼───────────┤\n",
      "│ y      │ (380000,)         │ (20000,)         │ (98000,)         │ (1,)      │\n",
      "╘════════╧═══════════════════╧══════════════════╧══════════════════╧═══════════╛\n",
      "\n",
      "╒══════════════╤═══════╤═══════╤════════╤═══════╤══════════════════════════╕\n",
      "│ Type         │   Min │   Max │   Mean │   Std │ Samples for each class   │\n",
      "╞══════════════╪═══════╪═══════╪════════╪═══════╪══════════════════════════╡\n",
      "│ Train Images │     0 │  1.48 │   0.02 │  0.09 │ [190000, 190000]         │\n",
      "├──────────────┼───────┼───────┼────────┼───────┼──────────────────────────┤\n",
      "│ Val Images   │     0 │  1.48 │   0.02 │  0.09 │ [10000, 10000]           │\n",
      "├──────────────┼───────┼───────┼────────┼───────┼──────────────────────────┤\n",
      "│ Test Images  │     0 │  1.47 │   0.02 │  0.09 │ [49000, 49000]           │\n",
      "╘══════════════╧═══════╧═══════╧════════╧═══════╧══════════════════════════╛\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = ElectronPhoton(args)\n",
    "data.prepare_data()\n",
    "data.setup()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dccd3ed6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-01T10:27:08.307277Z",
     "start_time": "2022-10-01T10:27:08.213526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_dims': (8, 8, 1), 'output_dims': (1,), 'mapping': [0, 1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51f6f84a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-01T10:28:50.449841Z",
     "start_time": "2022-10-01T10:27:15.566394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380000, 8, 8, 1) (20000, 8, 8, 1) (98000, 8, 8, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train =  tf_ds_to_numpy(data.train_ds) \n",
    "del data.train_ds\n",
    "\n",
    "x_val, y_val =  tf_ds_to_numpy(data.val_ds) \n",
    "del data.val_ds\n",
    "\n",
    "x_test, y_test =  tf_ds_to_numpy(data.test_ds) \n",
    "del data.test_ds\n",
    "\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72bfaf15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-01T10:29:08.236122Z",
     "start_time": "2022-10-01T10:29:00.108190Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_pairs(x, y):\n",
    "    \"\"\"Creates a tuple containing image pairs with corresponding label.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_classes = len(data.config()['mapping'])\n",
    "    digit_indices = [np.where(y == i)[0] for i in range(num_classes)]\n",
    "    pairs = []\n",
    "    labels = []\n",
    "\n",
    "    for idx1 in range(len(x)):\n",
    "        # add a matching example\n",
    "        x1 = x[idx1]\n",
    "        label1 = int(y[idx1])\n",
    "        idx2 = random.choice(digit_indices[label1])\n",
    "        x2 = x[idx2]\n",
    "\n",
    "        pairs += [[x1, x2]]\n",
    "        labels += [0]\n",
    "\n",
    "        # add a non-matching example\n",
    "        label2 = random.randint(0, num_classes - 1)\n",
    "        while label2 == label1:\n",
    "            label2 = random.randint(0, num_classes - 1)\n",
    "\n",
    "        idx2 = random.choice(digit_indices[label2])\n",
    "        x2 = x[idx2]\n",
    "\n",
    "        pairs += [[x1, x2]]\n",
    "        labels += [1]\n",
    "\n",
    "    return np.array(pairs), np.array(labels).astype(\"float32\")\n",
    "\n",
    "\n",
    "# make train pairs\n",
    "pairs_train, labels_train = make_pairs(x_train, y_train)\n",
    "del x_train, y_train\n",
    "# make validation pairs\n",
    "pairs_val, labels_val = make_pairs(x_val, y_val)\n",
    "del x_val, y_val\n",
    "# make test pairs\n",
    "pairs_test, labels_test = make_pairs(x_test, y_test)\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1fb3529",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-01T10:29:14.690803Z",
     "start_time": "2022-10-01T10:29:14.600644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(760000, 2, 8, 8, 1) (40000, 2, 8, 8, 1) (196000, 2, 8, 8, 1)\n",
      "(760000,) (40000,) (196000,)\n"
     ]
    }
   ],
   "source": [
    "print(pairs_train.shape, pairs_val.shape, pairs_test.shape)\n",
    "print(labels_train.shape, labels_val.shape, labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64754b87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-01T10:29:20.612768Z",
     "start_time": "2022-10-01T10:29:20.522226Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train_1 = pairs_train[:, 0]  # x_train_1.shape is (60000, 28, 28)\n",
    "x_train_2 = pairs_train[:, 1]\n",
    "\n",
    "del pairs_train\n",
    "\n",
    "x_val_1 = pairs_val[:, 0]  # x_val_1.shape = (60000, 28, 28)\n",
    "x_val_2 = pairs_val[:, 1]\n",
    "\n",
    "del pairs_val\n",
    "\n",
    "x_test_1 = pairs_test[:, 0]  # x_test_1.shape = (20000, 28, 28)\n",
    "x_test_2 = pairs_test[:, 1]\n",
    "\n",
    "del pairs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e577adc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-01T10:29:28.088526Z",
     "start_time": "2022-10-01T10:29:27.996958Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize(pairs, labels, to_show=6, num_col=3, predictions=None, test=False):\n",
    "    \"\"\"Creates a plot of pairs and labels, and prediction if it's test dataset.\n",
    "\n",
    "    Arguments:\n",
    "        pairs: Numpy Array, of pairs to visualize, having shape\n",
    "               (Number of pairs, 2, 28, 28).\n",
    "        to_show: Int, number of examples to visualize (default is 6)\n",
    "                `to_show` must be an integral multiple of `num_col`.\n",
    "                 Otherwise it will be trimmed if it is greater than num_col,\n",
    "                 and incremented if if it is less then num_col.\n",
    "        num_col: Int, number of images in one row - (default is 3)\n",
    "                 For test and train respectively, it should not exceed 3 and 7.\n",
    "        predictions: Numpy Array of predictions with shape (to_show, 1) -\n",
    "                     (default is None)\n",
    "                     Must be passed when test=True.\n",
    "        test: Boolean telling whether the dataset being visualized is\n",
    "              train dataset or test dataset - (default False).\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define num_row\n",
    "    # If to_show % num_col != 0\n",
    "    #    trim to_show,\n",
    "    #       to trim to_show limit num_row to the point where\n",
    "    #       to_show % num_col == 0\n",
    "    #\n",
    "    # If to_show//num_col == 0\n",
    "    #    then it means num_col is greater then to_show\n",
    "    #    increment to_show\n",
    "    #       to increment to_show set num_row to 1\n",
    "    num_row = to_show // num_col if to_show // num_col != 0 else 1\n",
    "\n",
    "    # `to_show` must be an integral multiple of `num_col`\n",
    "    #  we found num_row and we have num_col\n",
    "    #  to increment or decrement to_show\n",
    "    #  to make it integral multiple of `num_col`\n",
    "    #  simply set it equal to num_row * num_col\n",
    "    to_show = num_row * num_col\n",
    "\n",
    "    # Plot the images\n",
    "    fig, axes = plt.subplots(num_row, num_col, figsize=(5, 5))\n",
    "    for i in range(to_show):\n",
    "\n",
    "        # If the number of rows is 1, the axes array is one-dimensional\n",
    "        if num_row == 1:\n",
    "            ax = axes[i % num_col]\n",
    "        else:\n",
    "            ax = axes[i // num_col, i % num_col]\n",
    "\n",
    "        ax.imshow(tf.concat([pairs[i][0], pairs[i][1]], axis=1), cmap=\"gray\")\n",
    "        ax.set_axis_off()\n",
    "        if test:\n",
    "            ax.set_title(\"True: {} | Pred: {:.5f}\".format(labels[i], predictions[i][0]))\n",
    "        else:\n",
    "            ax.set_title(\"Label: {}\".format(labels[i]))\n",
    "    if test:\n",
    "        plt.tight_layout(rect=(0, 0, 1.9, 1.9), w_pad=0.0)\n",
    "    else:\n",
    "        plt.tight_layout(rect=(0, 0, 1.5, 1.5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a975a6dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-01T10:29:29.350385Z",
     "start_time": "2022-10-01T10:29:28.355160Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pairs_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26300/1404415660.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_show\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pairs_train' is not defined"
     ]
    }
   ],
   "source": [
    "visualize(pairs_train[:-1], labels_train[:-1], to_show=5, num_col=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9b9d58b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-01T10:29:47.591615Z",
     "start_time": "2022-10-01T10:29:46.698360Z"
    }
   },
   "outputs": [],
   "source": [
    "# Provided two tensors t1 and t2\n",
    "# Euclidean distance = sqrt(sum(square(t1-t2)))\n",
    "def euclidean_distance(vects):\n",
    "    \"\"\"Find the Euclidean distance between two vectors.\n",
    "\n",
    "    Arguments:\n",
    "        vects: List containing two tensors of same length.\n",
    "\n",
    "    Returns:\n",
    "        Tensor containing euclidean distance\n",
    "        (as floating point value) between vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = vects\n",
    "    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n",
    "\n",
    "\n",
    "input = layers.Input((8, 8, 1))\n",
    "\n",
    "# model = QCNNHybrid(data.config(), args)\n",
    "# x = model(input)\n",
    "# x = layers.Flatten()(x)\n",
    "\n",
    "input = layers.Input((8, 8, 1))\n",
    "x = tf.keras.layers.BatchNormalization()(input)\n",
    "x = layers.Conv2D(4, (3, 3), padding='same', activation=\"tanh\")(x)\n",
    "x = layers.AveragePooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Conv2D(16, (3, 3), padding='same', activation=\"tanh\")(x)\n",
    "x = layers.AveragePooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = layers.Dense(2, activation=\"tanh\")(x)\n",
    "embedding_network = keras.Model(input, x)\n",
    "\n",
    "\n",
    "input_1 = layers.Input((8, 8, 1))\n",
    "input_2 = layers.Input((8, 8, 1))\n",
    "\n",
    "# As mentioned above, Siamese Network share weights between\n",
    "# tower networks (sister networks). To allow this, we will use\n",
    "# same embedding network for both tower networks.\n",
    "tower_1 = embedding_network(input_1)\n",
    "tower_2 = embedding_network(input_2)\n",
    "\n",
    "merge_layer = layers.Lambda(euclidean_distance)([tower_1, tower_2])\n",
    "normal_layer = tf.keras.layers.BatchNormalization()(merge_layer)\n",
    "output_layer = layers.Dense(1, activation=\"sigmoid\")(normal_layer)\n",
    "siamese = keras.Model(inputs=[input_1, input_2], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58a391d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-01T10:29:49.322618Z",
     "start_time": "2022-10-01T10:29:49.230124Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss(margin=1):\n",
    "    \"\"\"Provides 'constrastive_loss' an enclosing scope with variable 'margin'.\n",
    "\n",
    "    Arguments:\n",
    "        margin: Integer, defines the baseline for distance for which pairs\n",
    "                should be classified as dissimilar. - (default is 1).\n",
    "\n",
    "    Returns:\n",
    "        'constrastive_loss' function with data ('margin') attached.\n",
    "    \"\"\"\n",
    "\n",
    "    # Contrastive loss = mean( (1-true_value) * square(prediction) +\n",
    "    #                         true_value * square( max(margin-prediction, 0) ))\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        \"\"\"Calculates the constrastive loss.\n",
    "\n",
    "        Arguments:\n",
    "            y_true: List of labels, each label is of type float32.\n",
    "            y_pred: List of predictions of same length as of y_true,\n",
    "                    each label is of type float32.\n",
    "\n",
    "        Returns:\n",
    "            A tensor containing constrastive loss as floating point value.\n",
    "        \"\"\"\n",
    "\n",
    "        square_pred = tf.math.square(y_pred)\n",
    "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
    "        return tf.math.reduce_mean(\n",
    "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
    "        )\n",
    "\n",
    "    return contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fe3dd98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-01T10:29:49.962944Z",
     "start_time": "2022-10-01T10:29:49.866047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 8, 8, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 8, 8, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 2)            1022        ['input_3[0][0]',                \n",
      "                                                                  'input_4[0][0]']                \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| input_2 (InputLayer)         [(None, 8, 8, 1)]    0           []                               |\n",
      "|                                                                                                |\n",
      "| batch_normalization (BatchNorm  (None, 8, 8, 1)   4           []                               |\n",
      "| alization)                                                                                     |\n",
      "|                                                                                                |\n",
      "| conv2d (Conv2D)              (None, 8, 8, 4)      40          []                               |\n",
      "|                                                                                                |\n",
      "| average_pooling2d (AveragePool  (None, 4, 4, 4)   0           []                               |\n",
      "| ing2D)                                                                                         |\n",
      "|                                                                                                |\n",
      "| conv2d_1 (Conv2D)            (None, 4, 4, 16)     592         []                               |\n",
      "|                                                                                                |\n",
      "| average_pooling2d_1 (AveragePo  (None, 2, 2, 16)  0           []                               |\n",
      "| oling2D)                                                                                       |\n",
      "|                                                                                                |\n",
      "| flatten (Flatten)            (None, 64)           0           []                               |\n",
      "|                                                                                                |\n",
      "| batch_normalization_1 (BatchNo  (None, 64)        256         []                               |\n",
      "| rmalization)                                                                                   |\n",
      "|                                                                                                |\n",
      "| dense (Dense)                (None, 2)            130         []                               |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " lambda (Lambda)                (None, 1)            0           ['model[0][0]',                  \n",
      "                                                                  'model[1][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 1)           4           ['lambda[0][0]']                 \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            2           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,028\n",
      "Trainable params: 896\n",
      "Non-trainable params: 132\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "margin = 1\n",
    "siamese.compile(loss=loss(margin=margin), optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
    "siamese.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a10e7c0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-10-01T10:29:54.732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2837/5938 [=============>................] - ETA: 29s - loss: 0.2539 - accuracy: 0.4977"
     ]
    }
   ],
   "source": [
    "history = siamese.fit(\n",
    "    [x_train_1, x_train_2],\n",
    "    labels_train,\n",
    "    validation_data=([x_val_1, x_val_2], labels_val),\n",
    "    batch_size=args.batch_size,\n",
    "    epochs=args.epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17232a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qenv)",
   "language": "python",
   "name": "qenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
