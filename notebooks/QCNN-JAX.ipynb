{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d28a72a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T04:29:14.807543Z",
     "start_time": "2022-08-18T04:29:10.402969Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from importlib.util import find_spec\n",
    "if find_spec(\"qml_hep_lhc\") is None:\n",
    "    import sys\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a7a9c90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T08:09:08.619045Z",
     "start_time": "2022-08-18T08:09:08.535530Z"
    }
   },
   "outputs": [],
   "source": [
    "from qml_hep_lhc.data import ElectronPhoton, MNIST, QuarkGluon\n",
    "from qml_hep_lhc.data.utils import tf_ds_to_numpy\n",
    "import argparse\n",
    "import wandb\n",
    "\n",
    "import pennylane as qml\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import optax\n",
    "from jax.nn.initializers import he_uniform\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Added to silence some warnings.\n",
    "# from jax.config import config\n",
    "# config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53cce28d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T04:30:25.676568Z",
     "start_time": "2022-08-18T04:30:25.256206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
       " TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
       " TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
       " TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
       " TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
       " TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
       " TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
       " TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7a7944e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:29:57.499669Z",
     "start_time": "2022-08-18T12:29:57.409023Z"
    }
   },
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n",
    "\n",
    "# Data\n",
    "# args.center_crop = 0.2\n",
    "# args.resize = [8,8]\n",
    "args.standardize = 1\n",
    "args.power_transform = 1\n",
    "# args.binary_data = [3,6]\n",
    "# args.percent_samples = 0.01\n",
    "# args.processed = 1\n",
    "args.dataset_type = '2'\n",
    "args.labels_to_categorical = 1\n",
    "args.batch_size = 128\n",
    "args.validation_split = 0.05\n",
    "\n",
    "# Base Model\n",
    "args.wandb = True\n",
    "args.epochs = 20\n",
    "args.learning_rate = 0.001\n",
    "\n",
    "# Quantum CNN Parameters\n",
    "args.n_layers = 2\n",
    "args.n_qubits = 4\n",
    "args.template = 'NQubitPQCSparse'\n",
    "args.initializer = 'he_uniform'\n",
    "\n",
    "args.kernel_size = (3,3)\n",
    "args.strides = (2,2)\n",
    "args.padding = \"VALID\"\n",
    "\n",
    "args.clayer_sizes = [8, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d347947e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:30:05.825415Z",
     "start_time": "2022-08-18T12:29:58.360985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/gopald/qml-hep-lhc/notebooks/wandb/run-20220822_105500-6ms9jhu9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/gopald/qml-hep-lhc/runs/6ms9jhu9\" target=\"_blank\">balmy-snow-277</a></strong> to <a href=\"https://wandb.ai/gopald/qml-hep-lhc\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if args.wandb:\n",
    "     wandb.init(project='qml-hep-lhc', config = vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ce4dec05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:30:09.713880Z",
     "start_time": "2022-08-18T12:30:05.831757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing power transform...\n",
      "Standardizing data...\n",
      "Converting labels to categorical...\n",
      "Converting labels to categorical...\n",
      "\n",
      "Dataset :Quark Gluon 2\n",
      "╒════════╤════════════════════╤═══════════════════╤════════════════════╤═════════════╕\n",
      "│ Data   │ Train size         │ Val size          │ Test size          │ Dims        │\n",
      "╞════════╪════════════════════╪═══════════════════╪════════════════════╪═════════════╡\n",
      "│ X      │ (95000, 40, 40, 1) │ (5000, 40, 40, 1) │ (20000, 40, 40, 1) │ (40, 40, 1) │\n",
      "├────────┼────────────────────┼───────────────────┼────────────────────┼─────────────┤\n",
      "│ y      │ (95000, 2)         │ (5000, 2)         │ (20000, 2)         │ (2,)        │\n",
      "╘════════╧════════════════════╧═══════════════════╧════════════════════╧═════════════╛\n",
      "\n",
      "╒══════════════╤═══════╤═══════╤════════╤═══════╤══════════════════════════╕\n",
      "│ Type         │   Min │   Max │   Mean │   Std │ Samples for each class   │\n",
      "╞══════════════╪═══════╪═══════╪════════╪═══════╪══════════════════════════╡\n",
      "│ Train Images │  -0.2 │ 14.61 │     -0 │  1    │ [47500, 47500]           │\n",
      "├──────────────┼───────┼───────┼────────┼───────┼──────────────────────────┤\n",
      "│ Val Images   │  -0.2 │ 14.61 │      0 │  1.01 │ [2500, 2500]             │\n",
      "├──────────────┼───────┼───────┼────────┼───────┼──────────────────────────┤\n",
      "│ Test Images  │  -0.2 │ 14.61 │      0 │  1    │ [10000, 10000]           │\n",
      "╘══════════════╧═══════╧═══════╧════════╧═══════╧══════════════════════════╛\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = QuarkGluon(args)\n",
    "data.prepare_data()\n",
    "data.setup()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74329b45",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "884dcb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dims = data.config()['input_dims']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "485ef1fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:30:12.534253Z",
     "start_time": "2022-08-18T12:30:12.416828Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_out_shape(in_shape, k, s, padding):\n",
    "    in_shape = (1,) + in_shape\n",
    "    a = np.random.uniform(size = (in_shape))\n",
    "    dn = jax.lax.conv_dimension_numbers(a.shape, (1,1,k[0],k[1]), ('NHWC', 'IOHW', 'NHWC'))\n",
    "    out = jax.lax.conv_general_dilated_patches(lhs = a,\n",
    "                                           filter_shape= k,\n",
    "                                           window_strides=s,\n",
    "                                           padding=padding,\n",
    "                                           dimension_numbers=dn \n",
    "                                    )\n",
    "    return out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b17ff04e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:30:13.114968Z",
     "start_time": "2022-08-18T12:30:13.018676Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gopald/qenv/lib/python3.8/site-packages/jax/_src/lax/other.py:97: UserWarning: Explicitly requested dtype float64 requested in eye is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  rhs = jnp.eye(spatial_size, dtype=lhs.dtype).reshape(filter_shape * 2)\n"
     ]
    }
   ],
   "source": [
    "initializer = he_uniform()\n",
    "\n",
    "# Get qlayer sizes\n",
    "def get_qlayer_sizes(template, n_l, n_q, k_size):\n",
    "    if template == 'NQubitPQCSparse':\n",
    "        return {\n",
    "            'w': (n_l, n_q,3,np.prod(k_size)),\n",
    "            'b': (n_l,n_q,3,1)\n",
    "        }\n",
    "    elif template == 'SimpleDRC':\n",
    "        return {\n",
    "            'w': (n_l+1,n_q,3),\n",
    "            's': (n_l,n_q),\n",
    "            'b': (n_l,n_q)\n",
    "        }\n",
    "    elif template == 'NQubitPQC':\n",
    "        assert np.prod(k_size)%3 == 0\n",
    "        return {\n",
    "            'w': (n_l,n_q,np.prod(k_size)),\n",
    "            'b': (n_l,n_q,np.prod(k_size))\n",
    "        }\n",
    "\n",
    "def random_qlayer_params(size, key, scale=1e-1):\n",
    "    return initializer(key, size)\n",
    "    return scale * random.normal(key, size)\n",
    "\n",
    "def init_qnetwork_params(sizes, key):\n",
    "    keys = random.split(key, len(sizes))\n",
    "    return [[random_qlayer_params(size, key) for size, key in zip(sizes.values(), keys)]]\n",
    " \n",
    "\n",
    "# A helper function to randomly initialize weights and biases\n",
    "# for a dense neural network layer\n",
    "def random_clayer_params(m, n, key, scale=1e-1):\n",
    "    w_key, b_key = random.split(key)\n",
    "    return initializer(w_key, (n,m)), random.normal(b_key, (n,))\n",
    "    return scale * random.normal(w_key, (n, m)), scale * random.normal(b_key, (n,))\n",
    "\n",
    "# Initialize all layers for a fully-connected neural network with sizes \"sizes\"\n",
    "def init_network_params(sizes, key):\n",
    "    keys = random.split(key, len(sizes))\n",
    "    return [random_clayer_params(m, n, k) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]\n",
    "\n",
    "kernel_size = args.kernel_size\n",
    "strides = args.strides\n",
    "padding = args.padding\n",
    "clayer_sizes = args.clayer_sizes\n",
    "\n",
    "template = args.template\n",
    "n_layers = args.n_layers\n",
    "n_qubits = args.n_qubits\n",
    "\n",
    "\n",
    "conv_out_shape = get_out_shape(input_dims, kernel_size, strides, padding)\n",
    "num_pixels = np.prod(conv_out_shape[:-1])*n_qubits\n",
    "qlayer_sizes = get_qlayer_sizes(template, n_layers, n_qubits, kernel_size)\n",
    "clayer_sizes = [num_pixels] + clayer_sizes\n",
    "\n",
    "params = []\n",
    "params += init_qnetwork_params(qlayer_sizes, random.PRNGKey(0))\n",
    "# params += init_qnetwork_params(qlayer_sizes, random.PRNGKey(1))\n",
    "params += init_network_params(clayer_sizes, random.PRNGKey(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5b368d89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:30:14.573933Z",
     "start_time": "2022-08-18T12:30:14.497315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4, 3, 9) (2, 4, 3, 1) \n",
      "(8, 1444) (8,) \n",
      "(2, 8) (2,) \n"
     ]
    }
   ],
   "source": [
    "for i in params:\n",
    "    for j in i:\n",
    "        print(j.shape, end = ' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc04079",
   "metadata": {},
   "source": [
    "## QLayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b5a64b72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:30:16.695492Z",
     "start_time": "2022-08-18T12:30:16.591237Z"
    }
   },
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit.jax', wires=n_qubits)\n",
    "qubits =list(range(n_qubits))\n",
    "\n",
    "@jax.jit\n",
    "@qml.qnode(dev, interface='jax')\n",
    "def NQubitPQCSparse(inputs, w, b):\n",
    "    z = jnp.dot(w, jnp.transpose(inputs))+ b\n",
    "\n",
    "    for q in qubits:\n",
    "        qml.Hadamard(wires=q)\n",
    "    \n",
    "    for l in range(n_layers):\n",
    "        for q in qubits:\n",
    "            qml.Rot(z[l,q,0], z[l,q,1], z[l,q,2], wires= q)\n",
    "        if (l & 1):\n",
    "            for q0, q1 in zip(qubits[1::2], qubits[2::2] + [qubits[0]]):\n",
    "                qml.CZ((q0,q1))\n",
    "        else:\n",
    "            for q0, q1 in zip(qubits[0::2], qubits[1::2]):\n",
    "                qml.CZ((q0,q1))\n",
    "   \n",
    "#     return qml.expval(qml.PauliZ(qubits[-1]))\n",
    "    return [qml.expval(qml.PauliZ(q)) for q in qubits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "caaf2386",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:30:18.863013Z",
     "start_time": "2022-08-18T12:30:18.775760Z"
    }
   },
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit.jax', wires=n_qubits)\n",
    "qubits =list(range(n_qubits))\n",
    "\n",
    "@jax.jit\n",
    "@qml.qnode(dev, interface='jax')\n",
    "def NQubitPQC(inputs, w, b):\n",
    "    steps = inputs.shape[-1]//3\n",
    "    for q in qubits:\n",
    "        qml.Hadamard(wires=q)\n",
    "    \n",
    "    for l in range(n_layers):\n",
    "        for q in qubits:\n",
    "            for i in range(steps):\n",
    "                z = jnp.transpose(jnp.multiply(inputs[:,3*i:3*i+3],w[l,q,3*i:3*i+3]) + b[l,q,3*i:3*i+3])\n",
    "                qml.RX(z[0], wires=q)\n",
    "                qml.RY(z[1], wires=q)\n",
    "                qml.RZ(z[2], wires=q)\n",
    "                \n",
    "        if (l & 1):\n",
    "            for q0, q1 in zip(qubits[1::2], qubits[2::2] + [qubits[0]]):\n",
    "                qml.CZ((q0,q1))\n",
    "        else:\n",
    "            for q0, q1 in zip(qubits[0::2], qubits[1::2]):\n",
    "                qml.CZ((q0,q1))\n",
    "\n",
    "#     return qml.expval(qml.PauliZ(qubits[-1]))\n",
    "    return [qml.expval(qml.PauliZ(q)) for q in qubits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6b9b34b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:30:19.590263Z",
     "start_time": "2022-08-18T12:30:19.497583Z"
    }
   },
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit.jax', wires=n_qubits)\n",
    "qubits =list(range(n_qubits))\n",
    "\n",
    "@jax.jit\n",
    "@qml.qnode(dev, interface='jax')\n",
    "def SimpleDRC(inputs, w, s, b):\n",
    "    for l in range(n_layers):\n",
    "        x = jnp.transpose(jnp.multiply(s[l],inputs) + b[l]) \n",
    "        for q in qubits:\n",
    "            qml.Rot(*w[l,q], wires = q)\n",
    "        for q0, q1 in zip(qubits, qubits[1:]):\n",
    "            qml.CZ((q0, q1))\n",
    "        if len(qubits) != 2:\n",
    "            qml.CZ((qubits[0], qubits[-1]))\n",
    "        for q in qubits:\n",
    "            qml.RX(x[q], wires=q)\n",
    "    for q in qubits:\n",
    "            qml.Rot(*w[n_layers,q], wires = q)\n",
    "   \n",
    "    return [qml.expval(qml.PauliZ(q)) for q in qubits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4b084fed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:30:19.987223Z",
     "start_time": "2022-08-18T12:30:19.883915Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_node(template):\n",
    "    if template == 'NQubitPQC':\n",
    "        return NQubitPQC\n",
    "    elif template == 'SimpleDRC':\n",
    "        return SimpleDRC\n",
    "    elif template == 'NQubitPQCSparse':\n",
    "        return NQubitPQCSparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "94ff6d15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:30:20.477017Z",
     "start_time": "2022-08-18T12:30:20.389789Z"
    }
   },
   "outputs": [],
   "source": [
    "def qconv(x, qweights):\n",
    "    x = jnp.expand_dims(x,axis=0)\n",
    "    dn = jax.lax.conv_dimension_numbers(x.shape, \n",
    "                                        (1,1,kernel_size[0],kernel_size[1]), \n",
    "                                        ('NHWC', 'IOHW', 'NHWC'))\n",
    "    x = jax.lax.conv_general_dilated_patches(lhs = x,\n",
    "                                               filter_shape= kernel_size,\n",
    "                                               window_strides=strides,\n",
    "                                               padding=padding,\n",
    "                                               dimension_numbers=dn \n",
    "                                              )\n",
    "    iters = x.shape[1:3]\n",
    "    x = jnp.reshape(x, (-1, np.prod(kernel_size)))\n",
    "    \n",
    "    x = get_node(template)(x, *qweights)\n",
    "    \n",
    "    x = jnp.reshape(x, iters + (n_qubits,))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d0ff8700",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:30:21.103675Z",
     "start_time": "2022-08-18T12:30:20.941594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ──H──Rot─╭●──Rot────╭Z─┤  <Z>\n",
      "1: ──H──Rot─╰Z──Rot─╭●─│──┤  <Z>\n",
      "2: ──H──Rot─╭●──Rot─╰Z─│──┤  <Z>\n",
      "3: ──H──Rot─╰Z──Rot────╰●─┤  <Z>\n"
     ]
    }
   ],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "qnode = qml.QNode(get_node(template), dev)\n",
    "\n",
    "inputs = np.random.uniform(size = (10,np.prod(kernel_size)))\n",
    "weights = params[0]\n",
    "drawer = qml.draw(qnode, expansion_strategy=\"device\")\n",
    "print(drawer(inputs,*weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb80645",
   "metadata": {},
   "source": [
    "## Auto-Batching Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "93945a8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:30:21.942507Z",
     "start_time": "2022-08-18T12:30:21.849352Z"
    }
   },
   "outputs": [],
   "source": [
    "from jax.scipy.special import logsumexp\n",
    "\n",
    "def relu(x):\n",
    "    return jnp.maximum(0, x)\n",
    "\n",
    "def forward(params, image):\n",
    "  # per-example predictions\n",
    "    activations = qconv(image, params[0])\n",
    "#     activations += image\n",
    "#     activations = relu(activations)\n",
    "    activations = jnp.reshape(activations, (-1))\n",
    "    for w, b in params[1:-1]:\n",
    "        outputs = jnp.dot(w, activations) + b\n",
    "        activations = relu(outputs)\n",
    "    final_w, final_b = params[-1]\n",
    "    logits = jnp.dot(final_w, activations) + final_b\n",
    "    return logits - logsumexp(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d8fa7746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardx(params, image):\n",
    "  # per-example predictions\n",
    "    activations = qconv(image, params[0])\n",
    "    activations = relu(activations)\n",
    "    activations = qconv(activations, params[1])\n",
    "    activations += image\n",
    "    activations = relu(activations)\n",
    "    \n",
    "    activations = jnp.reshape(activations, (-1))\n",
    "    for w, b in params[2:-1]:\n",
    "        outputs = jnp.dot(w, activations) + b\n",
    "        activations = relu(outputs)\n",
    "    final_w, final_b = params[-1]\n",
    "    logits = jnp.dot(final_w, activations) + final_b\n",
    "    return logits - logsumexp(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fbdb84a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:30:25.272029Z",
     "start_time": "2022-08-18T12:30:22.473112Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.11211586 -2.243807  ]\n"
     ]
    }
   ],
   "source": [
    "# This works on single examples\n",
    "random_flattened_image = random.normal(random.PRNGKey(1), input_dims)\n",
    "random_flattened_image = jnp.floor(random_flattened_image*10)\n",
    "preds = forward(params,  random_flattened_image)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "931e2120",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:30:25.363372Z",
     "start_time": "2022-08-18T12:30:25.277464Z"
    }
   },
   "outputs": [],
   "source": [
    "# Doesn't work with a batch\n",
    "random_flattened_images = random.normal(random.PRNGKey(1), (2,)+ input_dims)\n",
    "random_flattened_images = jnp.floor(random_flattened_images*10)\n",
    "# try:\n",
    "#     preds = predict(params, random_flattened_images)\n",
    "# except TypeError:\n",
    "#     print('Invalid shapes!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9fa9ea5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:30:28.950189Z",
     "start_time": "2022-08-18T12:30:25.366517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.         -19.149054  ]\n",
      " [ -2.0530276   -0.13735485]]\n"
     ]
    }
   ],
   "source": [
    "# Let's upgrade it to handle batches using `vmap`\n",
    "\n",
    "# Make a batched version of the `predict` function\n",
    "batched_forward = vmap(forward, in_axes=(None,0))\n",
    "\n",
    "# `batched_predict` has the same call signature as `predict`\n",
    "batched_preds = batched_forward(params, random_flattened_images)\n",
    "print(batched_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d696d399",
   "metadata": {},
   "source": [
    "## Utility and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fc48796a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:30:29.057547Z",
     "start_time": "2022-08-18T12:30:28.957309Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    target_class = jnp.argmax(y_true, axis=1)\n",
    "    predicted_class = jnp.argmax(y_pred, axis=1)\n",
    "    return jnp.mean(predicted_class == target_class)\n",
    " \n",
    "\n",
    "def loss_fn(params, images, targets):\n",
    "    preds = batched_forward(params, images)\n",
    "    loss_value = -jnp.mean(preds * targets)\n",
    "    return loss_value, preds\n",
    "\n",
    "@jit\n",
    "def update(opt_state, params, x, y):\n",
    "    (loss_value, preds), grads = jax.value_and_grad(loss_fn, has_aux=True)(params, x, y)\n",
    "    acc = accuracy(y,preds)\n",
    "    \n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    \n",
    "    return params, opt_state, loss_value, acc \n",
    "\n",
    "\n",
    "def step(params,x,y):\n",
    "    loss_value, preds = loss_fn(params, x, y)\n",
    "    acc = accuracy(y, preds)\n",
    "    return loss_value, acc\n",
    "\n",
    "def evaluate(params, ds):\n",
    "    losses = []\n",
    "    accs = []\n",
    "    with tqdm(tfds.as_numpy(ds), unit=\"batch\") as tepoch:\n",
    "        for x, y in tepoch:\n",
    "            loss_value, acc = step(params, x, y)\n",
    "            losses.append(loss_value)\n",
    "            accs.append(acc)\n",
    "            tepoch.set_postfix(loss=loss_value, acc=acc)\n",
    "            \n",
    "    return jnp.mean(np.array(losses)), jnp.mean(np.array(accs))\n",
    "\n",
    "def predict(params, ds):\n",
    "    preds = []\n",
    "    y_true = []\n",
    "    with tqdm(tfds.as_numpy(ds), unit=\"batch\") as tepoch:\n",
    "        for x, y in tepoch:\n",
    "            preds += list(batched_forward(params, x))\n",
    "            y_true += list(y)\n",
    "    \n",
    "    return np.array(preds), np.array(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afa04b",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0c29b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "01c9e9c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:30:29.181675Z",
     "start_time": "2022-08-18T12:30:29.065879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "schedule_fn = optax.linear_schedule(transition_steps=150,\n",
    "                                    init_value=0.2,\n",
    "                                    end_value=1e-7,\n",
    "                                    )\n",
    "# Defining an optimizer in Jax \n",
    "# optimizer = optax.adam(learning_rate=schedule_fn)\n",
    "\n",
    "print(lr)\n",
    "optimizer = optax.adam(learning_rate=args.learning_rate)\n",
    "# optimizer = optax.adam(learning_rate=lr)\n",
    "opt_state = optimizer.init(params)\n",
    "lr = (lr*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f365f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:31:13.791757Z",
     "start_time": "2022-08-18T12:30:32.206391Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████████████████████████████| 743/743 [09:09<00:00,  1.35batch/s, acc=0.5416667, loss=0.34963474]\n",
      "100%|█████████████████████████████████████████████████| 40/40 [00:12<00:00,  3.33batch/s, acc=0.375, loss=0.38454804]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3442888855934143 - val_acc: 0.5472656488418579-  time: 549.2657237052917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|███████████████████████████████████| 743/743 [08:55<00:00,  1.39batch/s, acc=0.2916667, loss=0.3705942]\n",
      "100%|█████████████████████████████████████████████████| 40/40 [00:05<00:00,  7.71batch/s, acc=0.625, loss=0.33907646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.34018948674201965 - val_acc: 0.573046863079071-  time: 535.5697953701019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|████████████████████████████████████████| 743/743 [08:55<00:00,  1.39batch/s, acc=0.5, loss=0.36190435]\n",
      "100%|█████████████████████████████████████████████████| 40/40 [00:05<00:00,  7.71batch/s, acc=0.875, loss=0.32057077]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3337971270084381 - val_acc: 0.6048828363418579-  time: 535.4961884021759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|████████████████████████████████████████| 743/743 [08:55<00:00,  1.39batch/s, acc=0.5, loss=0.37026352]\n",
      "100%|██████████████████████████████████████████████████| 40/40 [00:05<00:00,  7.72batch/s, acc=0.75, loss=0.36012775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3312808573246002 - val_acc: 0.6117187738418579-  time: 535.2245771884918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████| 743/743 [08:55<00:00,  1.39batch/s, acc=0.5, loss=0.36378896]\n",
      "100%|█████████████████████████████████████████████████| 40/40 [00:05<00:00,  7.74batch/s, acc=0.875, loss=0.25919777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.32500097155570984 - val_acc: 0.624218761920929-  time: 535.2908368110657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|███████████████████████████████████████| 743/743 [08:55<00:00,  1.39batch/s, acc=0.625, loss=0.3116935]\n",
      "100%|█████████████████████████████████████████████████████| 40/40 [00:05<00:00,  7.74batch/s, acc=0.75, loss=0.29148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.32319164276123047 - val_acc: 0.6244140863418579-  time: 535.302996635437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████████████████████████████| 743/743 [08:55<00:00,  1.39batch/s, acc=0.5833334, loss=0.32310146]\n",
      "100%|███████████████████████████████████████████████████| 40/40 [00:05<00:00,  7.74batch/s, acc=0.5, loss=0.38066936]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.32493677735328674 - val_acc: 0.620312511920929-  time: 535.4283833503723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|███████████████████████████████████| 743/743 [08:55<00:00,  1.39batch/s, acc=0.5833334, loss=0.3202511]\n",
      "100%|█████████████████████████████████████████████████| 40/40 [00:05<00:00,  7.71batch/s, acc=0.125, loss=0.46611574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3265770375728607 - val_acc: 0.6162109375-  time: 535.4490578174591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|███████████████████████████████████████| 743/743 [08:55<00:00,  1.39batch/s, acc=0.75, loss=0.26556504]\n",
      "100%|██████████████████████████████████████████████████| 40/40 [00:05<00:00,  7.74batch/s, acc=0.75, loss=0.32307842]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3219431936740875 - val_acc: 0.6363281607627869-  time: 535.3652205467224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████████████████████████████████| 743/743 [08:55<00:00,  1.39batch/s, acc=0.625, loss=0.35050088]\n",
      "100%|█████████████████████████████████████████████████| 40/40 [00:05<00:00,  7.73batch/s, acc=0.625, loss=0.32838377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3223625719547272 - val_acc: 0.6357421875-  time: 535.4385662078857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|█████████████████████████████████| 743/743 [08:55<00:00,  1.39batch/s, acc=0.5833334, loss=0.32374728]\n",
      "100%|██████████████████████████████████████████████████| 40/40 [00:05<00:00,  7.72batch/s, acc=0.75, loss=0.23875633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3204209506511688 - val_acc: 0.6363281607627869-  time: 535.3487136363983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|█████████████████████████████████| 743/743 [08:55<00:00,  1.39batch/s, acc=0.5833334, loss=0.34833393]\n",
      "100%|██████████████████████████████████████████████████| 40/40 [00:05<00:00,  7.73batch/s, acc=0.75, loss=0.22770637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3192037045955658 - val_acc: 0.6429687738418579-  time: 535.4102993011475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12:  43%|██████████████▌                   | 317/743 [03:49<05:07,  1.39batch/s, acc=0.671875, loss=0.30435002]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "epochs = args.epochs\n",
    "# epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    with tqdm(tfds.as_numpy(data.train_ds), unit=\"batch\") as tepoch:\n",
    "        for x, y in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "            params, opt_state, loss_value, acc = update(opt_state, params, x, y)\n",
    "            tepoch.set_postfix(loss=loss_value, acc=acc)\n",
    "        \n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    val_loss, val_acc = evaluate(params, data.val_ds)\n",
    "    print('val_loss: {} - val_acc: {}-  time: {}'.format(val_loss, val_acc, epoch_time))\n",
    "    \n",
    "    if args.wandb:\n",
    "        wandb.log({\"accuracy\": acc, \n",
    "                   \"val_accuracy\": val_acc, \n",
    "                   'loss':loss_value, \n",
    "                   'val_loss':val_loss})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfafc1ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:31:18.234069Z",
     "start_time": "2022-08-18T12:31:13.797326Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = evaluate(params, data.test_ds)\n",
    "test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4571ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "out,y_test = predict(params, data.test_ds)\n",
    "# _, y_test = tf_ds_to_numpy(data.test_ds)\n",
    "test_auc = roc_auc_score(y_test, out)\n",
    "test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6ffd07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:31:47.449894Z",
     "start_time": "2022-08-18T12:31:45.674085Z"
    }
   },
   "outputs": [],
   "source": [
    "if args.wandb:\n",
    "    wandb.run.summary['test_loss'] = test_loss\n",
    "    wandb.run.summary['test_acc'] = test_acc\n",
    "    wandb.run.summary['test_auc'] = test_auc\n",
    "    y = y_test.argmax(axis=1)\n",
    "    preds = out.argmax(axis=1)\n",
    "    probs = out\n",
    "    classes = data.mapping\n",
    "\n",
    "    roc_curve = wandb.sklearn.plot_roc(y, probs, classes)\n",
    "    confusion_matrix = wandb.sklearn.plot_confusion_matrix(y, preds, classes)\n",
    "\n",
    "    wandb.log({\"roc_curve\": roc_curve})\n",
    "    wandb.log({\"confusion_matrix\": confusion_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d256c76d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:32:01.828384Z",
     "start_time": "2022-08-18T12:31:48.539691Z"
    }
   },
   "outputs": [],
   "source": [
    "if args.wandb:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e98b225",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T05:06:41.426383Z",
     "start_time": "2022-08-18T05:06:41.265770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.2\n",
      "1 0.19866668\n",
      "2 0.19733334\n",
      "3 0.19600001\n",
      "4 0.19466668\n",
      "5 0.19333333\n",
      "6 0.192\n",
      "7 0.19066668\n",
      "8 0.18933333\n",
      "9 0.18800001\n",
      "10 0.18666668\n",
      "11 0.18533334\n",
      "12 0.18400002\n",
      "13 0.18266669\n",
      "14 0.18133333\n",
      "15 0.18\n",
      "16 0.17866668\n",
      "17 0.17733334\n",
      "18 0.17600001\n",
      "19 0.17466669\n",
      "20 0.17333335\n",
      "21 0.17200002\n",
      "22 0.1706667\n",
      "23 0.16933335\n",
      "24 0.16800003\n",
      "25 0.16666669\n",
      "26 0.16533335\n",
      "27 0.16400002\n",
      "28 0.1626667\n",
      "29 0.16133335\n",
      "30 0.16000003\n",
      "31 0.15866669\n",
      "32 0.15733334\n",
      "33 0.15600002\n",
      "34 0.15466669\n",
      "35 0.15333335\n",
      "36 0.15200002\n",
      "37 0.1506667\n",
      "38 0.14933336\n",
      "39 0.14800003\n",
      "40 0.1466667\n",
      "41 0.14533336\n",
      "42 0.14400004\n",
      "43 0.14266671\n",
      "44 0.14133336\n",
      "45 0.14000003\n",
      "46 0.1386667\n",
      "47 0.13733336\n",
      "48 0.13600004\n",
      "49 0.1346667\n",
      "50 0.13333336\n",
      "51 0.13200003\n",
      "52 0.1306667\n",
      "53 0.12933336\n",
      "54 0.12800004\n",
      "55 0.12666671\n",
      "56 0.12533337\n",
      "57 0.124000035\n",
      "58 0.1226667\n",
      "59 0.121333376\n",
      "60 0.12000004\n",
      "61 0.11866671\n",
      "62 0.11733337\n",
      "63 0.116000034\n",
      "64 0.1146667\n",
      "65 0.113333374\n",
      "66 0.11200004\n",
      "67 0.1106667\n",
      "68 0.109333366\n",
      "69 0.10800003\n",
      "70 0.10666671\n",
      "71 0.10533337\n",
      "72 0.10400004\n",
      "73 0.102666706\n",
      "74 0.10133338\n",
      "75 0.100000046\n",
      "76 0.09866671\n",
      "77 0.09733339\n",
      "78 0.09600004\n",
      "79 0.09466671\n",
      "80 0.09333338\n",
      "81 0.092000045\n",
      "82 0.09066671\n",
      "83 0.089333385\n",
      "84 0.08800005\n",
      "85 0.08666672\n",
      "86 0.08533339\n",
      "87 0.08400004\n",
      "88 0.08266672\n",
      "89 0.081333384\n",
      "90 0.08000005\n",
      "91 0.07866672\n",
      "92 0.07733339\n",
      "93 0.07600006\n",
      "94 0.07466672\n",
      "95 0.0733334\n",
      "96 0.072000064\n",
      "97 0.07066672\n",
      "98 0.06933339\n",
      "99 0.068000056\n",
      "100 0.06666672\n",
      "101 0.065333396\n",
      "102 0.06400006\n",
      "103 0.06266673\n",
      "104 0.061333403\n",
      "105 0.060000073\n",
      "106 0.05866673\n",
      "107 0.0573334\n",
      "108 0.056000065\n",
      "109 0.054666735\n",
      "110 0.053333405\n",
      "111 0.05200007\n",
      "112 0.050666742\n",
      "113 0.04933341\n",
      "114 0.04800008\n",
      "115 0.046666734\n",
      "116 0.045333404\n",
      "117 0.04400007\n",
      "118 0.04266674\n",
      "119 0.04133341\n",
      "120 0.040000077\n",
      "121 0.038666748\n",
      "122 0.037333414\n",
      "123 0.036000084\n",
      "124 0.03466674\n",
      "125 0.03333341\n",
      "126 0.032000076\n",
      "127 0.030666746\n",
      "128 0.029333415\n",
      "129 0.028000083\n",
      "130 0.026666753\n",
      "131 0.025333421\n",
      "132 0.02400009\n",
      "133 0.022666747\n",
      "134 0.021333415\n",
      "135 0.020000083\n",
      "136 0.018666752\n",
      "137 0.01733342\n",
      "138 0.016000088\n",
      "139 0.014666757\n",
      "140 0.013333426\n",
      "141 0.012000094\n",
      "142 0.01066675\n",
      "143 0.00933342\n",
      "144 0.008000088\n",
      "145 0.006666757\n",
      "146 0.0053334255\n",
      "147 0.0040000943\n",
      "148 0.0026667626\n",
      "149 0.0013334313\n",
      "150 1e-07\n",
      "151 1e-07\n",
      "152 1e-07\n",
      "153 1e-07\n",
      "154 1e-07\n",
      "155 1e-07\n",
      "156 1e-07\n",
      "157 1e-07\n",
      "158 1e-07\n",
      "159 1e-07\n",
      "160 1e-07\n",
      "161 1e-07\n",
      "162 1e-07\n",
      "163 1e-07\n",
      "164 1e-07\n",
      "165 1e-07\n",
      "166 1e-07\n",
      "167 1e-07\n",
      "168 1e-07\n",
      "169 1e-07\n",
      "170 1e-07\n",
      "171 1e-07\n",
      "172 1e-07\n",
      "173 1e-07\n",
      "174 1e-07\n",
      "175 1e-07\n",
      "176 1e-07\n",
      "177 1e-07\n",
      "178 1e-07\n",
      "179 1e-07\n",
      "180 1e-07\n",
      "181 1e-07\n",
      "182 1e-07\n",
      "183 1e-07\n",
      "184 1e-07\n",
      "185 1e-07\n",
      "186 1e-07\n",
      "187 1e-07\n",
      "188 1e-07\n",
      "189 1e-07\n",
      "190 1e-07\n",
      "191 1e-07\n",
      "192 1e-07\n",
      "193 1e-07\n",
      "194 1e-07\n",
      "195 1e-07\n",
      "196 1e-07\n",
      "197 1e-07\n",
      "198 1e-07\n",
      "199 1e-07\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    print(i, schedule_fn(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bd7ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
